Incompetent, or maybe not paid enough to really give a damn. Not to mention I said from the start that CPU coins are a fucking stupid idea because even a tiny botnet can trivially 51% em.So... *what* is that "trivial" bug, and how the fuck do you work around it? Oh right... "seekrit! neener neener!"Getting tired of calling me incompetent yet? No? Okay. keep on then...So wait, I'm supposed to release a SC2 GPU miner to the public out of the goodness of my heart when you fuckwads publically spread defamatory comments about me? Kindly go fuck yourself.As for how much GPU mining I have been doing, I had 24 5970s up until about late summer '11... then sold em, because at 0.22EUR/kWh keeping a mining farm after that would be kinda ... stupid, no?And as for me publically admitting I gave away a SC2 GPU miner? well, did I ever claim otherwise? ... Wait, nobody ever asked! Just LOL ARTFORZ IS DICKMINER trolling from you, which I can honestly claim is false. Now if you said LOL ARTFORZ WROTE A SC2 MINER BY REING SC2 BETA AND GIVES IT TO WHOEVER ASKS... that'd be different. But no one ever came close to that.So, let's play that game in reverse... why didn't any of your guys come up with the trivial optimization of turning the (really expensive on a GPU) 64 bit modulos in SC2s algo into (cheap) 32 bit sum-and-mod with carry? In months? Waaait, let me guess, they're all incompetent ... or they did. But hey, no reason to let those "parasite" miners outside of your inner circle have it, right? Well, from talking with Ahimoth on btc-e, sounds like mtrlt managed to find a workaround for the issues I was having with scrypt miner kernels on GPU.Short version... any of my kernels that got speeds like that also got 100% invalids. Yet the same kernel worked fine on CPU or if I dropped global and/or local worksizes to silly small levels... which of course made it dog slow again...And of course RS turning the whole thing into "OMG CONSPIRACY!!1one"... duh, it's RS. What previous posters have said, SuperFlower 80+ gold/platinum platform (which this is...) == kickassOh, and WTF is CoolerMaster doing on that list? They have PLENTY of crap in their low-mid range, had a GX750 burn up running 2 5970s... True for mining. Now measure slot 12V current while actually doing something that gives the memory a workout, you'll be surprised  Says who?Check PCIe CEM spec section 4.2.4, then claim that again. So far haven't heard of problems with < 4 single GPU or 3 dual GPU cards, and considering 2 single cards is a normal SLI/Xfire setup, I'd think we'd see plenty complaining in gamer forums if it'd cause problems. Short version: compared to (1024,1,1) increasing N and r actually helps GPUs and hurts CPUs.Longer version:While things are small enough to fit in L2, each CPU core can act mostly independently and has pretty large read/write BW, make it big enough to hit external memory and you've got ~15GB/s shared between all cores.Meanwhile, GPU caches are too small to be of much use, so... with random reads at 128B/item a 256 bit GDDR5 bus ends up well < 20% peak BW, at 1024B/item that % increases very significantly.end result, a 5870 ends up about 6 times as fast as a PhenomII for scrypt(8192,8,1). (without really trying to optimize either side, so ymmv).The only way to make scrypt win on CPU-vs-GPU again would be to go WAAAY bigger, think > 128MB V array so you don't have enough RAM on GPUs to run enough parallel instances to mask latencies... but that also means it's REALLY slow (hash/sec? sec/hash!) and you need the same amount of memory to check results... Now who wants a *coin where a normal node needs several seconds and 100s of megs to gigs of ram just to check a block PoW for validity? Well, 7.5A/core was ok for a 192-205MHz 122-round 2-stage-per-round pipeline design. Just my later designs needed more power.Also, unless I misremember, he uses ultra-low-esl 0306 caps for vccint, xilinx recommended #s are for caps with ESL values similar to 0402s... so... prolly fine.Yep, that's the picture... Still don't get why on earth they did it that way. A AC->12V PSU and half a dozen or so point-of-load converters would've saved a whole lot of copper (and prevent accidentally welding holes in your chassis...) LOL. Priceless. First one has a shared 10A reg for 2 LX150s -> max of 5A vccint each.Second has a 12A for 4 LX150s -> 3A eachMy early LX150 miner prototypes had a 60A switcher for vccint for 8 chips -> 7.5A each... and that later turned out to be not enough.Btw, one thing that made me go WTF when looking at interior pics of copacobana a few years ago... a single massive AC->1.2V converter for vccint and really heavy cables + busbars to route it around... You either got a bad card or some seriously bad case airflow there...0. SI TAHITI XT (:0.0)    engine clock 1170MHz, memory clock 1070MHz, core voltage 1.17VDC, performance level 2, utilization 99%    fan speed 43% (2408 RPM) (default)    temperature 72 C    Powertune 10% Okay, let me explain it again in SMALL WORDS.VDDCI is memory controller voltage. Not memory voltage.Memory voltage (MVDDC/MVDDQ) is from the 2 non-software-controllable VT243s (VT237s on 5970s).Non-software-controllable. As in "needs hardmod to change".now, on to VDDCI, which *is* software controllable on reference 5870s and 5970s.It's already possible to play with it in linux with a trivial modification to radeonvolt as it's a vt1165 like VDDC, just at i2c addr 0x71 instead of 0x70.So... how much power can you save lowering it? on a 5970 mining @ 300 memclock, reducing it from 1.05 to 0.90 drops total power/card by ~ 1W...Yeah. It's the VDDCI VRM. it does VDDCI Seriously, VDDCI = "uncore" ... as far as I can tell it's PCIe and memory controller core voltage. Read carefully, that's a 5870 *and* a 7970... 880Mh is awful.7970 is ~550Mh/s stock5870 is ~380Mh/s stockso that's > 5% slower than what they should be doing... on ref 5870 that VRM slave with a missing brother in the top left is the VDDCI, its vt1165 controller is in the extreme top left corner.memory VDD is the 2 above the missing 5th VDDC phase on the right (looks like those 2 are actually set up to run as a 2-phase... hard to tell from tiny pics)on nonrefs... well, anything can be anywhere edit: nope, those 2 are 2 single vt243s, most likely memory VDDC and VDDQ If you look closely, you'll find several more VRMs on the 5970first the obvious ones:VRM1 area = VT1165 + 3 slaves, GPU1 VDDC (i2c slave addr 0x70 on gpu1)VRM2 area = VT1165 + 3 slaves, GPU2 VDDC (i2c slave addr 0x70 on gpu2)the square chip at the top/right of vrm2 area = another vt1165 controller, belongs to the 2 slaves above the VRM2 slaves, it's a 2-phase providing both GPUs VDDCI (i2c slave addr 0x71 on gpu1)now, there's avolterra integrated controller (vt237) top/right of the 1 of "VRM1"and another vt237 under the R of "VRM2"I suspect those 2 guys are our memory VCC (one for each GPUs memory?).now on to the non-volterra stuffa AOZ1024D above the VDDCI inductors and output caps... no clue.the 2 FETs below the GPU2 memory chips/left of the suspected GPU2 memory VRM, controller is a uP6101 on the backside ... again, random aux supply.that should be it for major switchers, there's probably another 3 or 4 linear regs strewn about... No, it's always been at war with Eurasia. Well a quantum leap is the smallest possible change, so... it's a quantum leap Honestly, for mining I'd prefer 5970s. At least until we get 7990s.What's somewhat surprising is what a power hog a idle 5970 is, didn't quite expect it to be *that* bad. all on the same rigPhenomII @ 1GHz, PSU is the same SF 80+ gold as used before5970, linux amd64, cat 11.12, sdk2.5idle @ 0.95V/157/1000, 182Widle @ 0.95V/157/300, 152Widle @ 0.95V/157/150, 149Wcgminer @ 1.05V/820/300, 377W, 761Mh/scgminer @ 1.05V/600/150, 308W, 542Mh/scgminer @ 1.00V/600/150, 291W, 542Mh/scgminer @ 0.95V/600/150, 273W, 542Mh/s7970, linux amd64, cat 11.12, sdk2.6idle @ 0.85V/300/150, 115Widle @ 1.175V/300/150, 132Widle @ 1.175V/1150/1070, 168Wphoenix @ 1.175V/1150/1070, 363W, 676Mh/sphoenix @ 1.175V/1150/1375, 370W, 676Mh/sphoenix @ 0.85V/300/200, 154W, 178Mh/s7970, windows 7, cat 11.12 7970 edition, sdk 2.6screen off for a bit,102Widle @ 0.85V/300/150, 114Widle @ 1.175V/925/150, 142Widle @ 1.0V/925/150, 128Wphoenix @ 1.0V/925/150, 235W, 535Mh/sphoenix @ 0.95V/925/150, 222W, 535Mh/sphoenix @ 0.92V/925/150, 217W, 535Mh/sphoenix @ 1.175V/1150/150, 328W, 659Mh/sphoenix @ 1.175V/1150/300, 339W, 666Mh/sphoenix @ 1.175V/1150/1070, 368W, 674Mh/s2MB PCI S3 VGA card, linuxidle 101Wso let's run some numbers, using 0.95V as undervolt for 7970...whole system:max OC @ stock V: 5970 2.02Mh/J, 7970 2.01undervolted: 5970 1.99Mh/J, 7970 2.41assuming system is 100W (well, more or less...)max OC @ stock V: 5970 2.75Mh/J, 7970 2.89undervolted: 5970 3.13Mh/J, 7970 4.39bullshit calc (aka simple load - idle)max OC @ stock V: 5970 3.38Mh/J, 7970 3.07undervolted: 5970 4.37Mh/J, 7970 4.95 PSU? What else are you going to run your FPGAs off of? A few dozen <75% efficient chinese wall warts?HDD? USB stick or CF card in PATA adapter. Even a 7.2k 2.5" is <1W spinning.Mobo? I give you that, 3.5W vs. 20W peak ...So we're talking about 430 vs 450W for 10Gh with S6s, 23.3 vs. 22.2 Mh/J ... not exactly a massive deal.For something with efficiency similar to BFLs vaporboards, it's even less of a difference, 2-3% max.Now, what something like a pi does have going for it is power (see above, not *that* big of an issue), cost and size. = A lot cheaper, and way easier to tuck into a corner somewhere.Benefits of a generic x86 ... can install any random OS, way easier to set up a full dev toolchain without having to fiiddle with crosscompiling, > 256MB RAM. Also potentially a lot faster and has GigE (somewhat pointless here...).So yeah, if I wanted to build a few dozen 10Gh rigs something like the pi as a controller would make sense... for a one-off... too much work, just slap a x86 in.
50-70W? For a atom or via board? In what universe? Had the same thing once, pulling the plug + 10 min wait magically fixed it. +1 for MSI 890FXA-GD703 cards in standard cases with airspace, can do 6 cards with risers, 6-pin connector onboard so no need for powered risers.And +1 on "don't put cards right next to each other, unless you like overheating cards and dead fans". Well, if that's your guess... I could tell you what that's *very* unlikely, but... meh. I'd stay away from Scythe UKs, got a box full of em. Sleeve bearings shot after a few months @ 100%.Btw, OEM of the Scythe UK line is Young Lin Tech Co.If you're looking for decent rad fans in the size/power category of a UK3k...delta afb1212hhepanaflo fba12g12u...or really pretty much anything 120x120x38 from a reputable mfg. with ball bearings and 5-7W. Yeah, a FF784 package on a FF780 footprint. right.While we're making random shit up, EP3SL70 or 110 (can't see any way to fit 120 rounds in a SL50, even 64 single-stage rounds is pushing it). Can't set anything lower, when I try it *shows* lower but jumps back to 1375 (obvious in power consumption @ 925 core) I'd subtract 108W or so, should get decent estimate of real card power at the wall with a 92% efficient PSU. *shame* disregard those results, somehow managed to completely botch it.I think I mixed up hashrates, clocks and power measurements from different sets of runs or skipped lines somehwere.Great, have to throw all data out and start over :/Phenom II 1100T @ 4.0GHz, cpu freq scaling disabled.idle, display off 122Widle @ desktop 139Wphoenix 1.7.3, -k poclbm AGGRESSION=10 WORKSIZE=256stock V @ 50% fan925 core/1375 mem, 554 Mh/s, 369W925 core/1020 mem, 554 Mh/s, 360W1070 core/1020 mem, 640 Mh/s, 386W1170 core/1020 mem, 698 Mh/s, 407W1.20 V @ 55% fan1170 core/1020 mem, 698 Mh/s, 421W1200 core/1020 mem, 714 Mh/s, 428W1240 core/1020 mem, 736 Mh/s, 431W1.25V @ 70% fan1240 core/1020 mem, 736 Mh/s, 467W1270 core/1020 mem, 753 Mh/s, 476W1.30V @ 80% fan1270 core/1020 mem, 753 Mh/s, 509W1350 core/1020 mem, 799 Mh/s, 525Wnot sure how I got 695/759/804, guess that was a run at 1375 mem Now, after massive thread derailment... back to OPs question.stock vs. stock 2*6870 easily beats 6970. 2*~290 = ~580 vs. ~390 for a 6970. Well, iirc GPU-Z shader # is simply based off a hardcoded table of device IDs, so that's no big help either.Atm I'm out of ideas of how to figure out what is really going on there, just seems *very* odd that your 5850 is 11% faster than what everyone else is reporting, and 111% just happens to be very close to 1600/1440. Yeah, but the PCI device ID says it's supposed to be a 5850...Honestly not sure WTF to make of that, all I get is "congratulations, you're the proud owner of a 5850 with 1600 enabled shaders." It's rather simple to convert between cards of the same family, mining scales pretty much 100% with #shaders * clock.430Mh/s / 930MHz / 1440 shaders = 0.000321087 hash/shaderclock0.000321087 hash/shaderclock * 850 MHz = 272923.95 hash/shadersecond272923.95 hash/shadersecond * 1600 shaders = 436678320 hash/sec.so to convert, it's generally simply hashrateA / clockA / #shadersA * clockB * #shadersB Nope, haven't found any better settings than what other people have been saying for Diablo, best I found was ~2.2% worse than phoenix. 430Mh/s at 930 core on a 58*50*?That'd be 335Mh/s stock. On a 5850.Or 436Mh/s on a stock 5870.So... why is everyone else reporting numbers *way* below that? Just tried it for shits and giggles... 7970 primary, 6870 secondary w/ the 7970 drivers from AMDs site for windows and 11.12 for linux. works. Quick calc says we're already a few % higher hashrate/shader/clock than VLIWx.I'd have to take a closer look at how GCN shader ASM looks and what engine performance is like, but wouldn't expect any miracles, maybe another 2-3% increase.So my opinion so far "pretty much a wash, a hair better than 5xxx per shader per clock, may get another few % when more time is spent tuning kernels for GCN".Mining is really unique in how it manages to get well > 90% peak throughput even on VLIW5  Now that I can agree with.The work required to add OpenCL support is pretty massive, and AFAIK there's pretty much 0 done on a open source OpenCL -> VLIWx shader asm compiler, several other large parts of the puzzle are also completely missing (runtime, runtime/opengl/driver integration/...).But saying that the open source driver can't use shaders is wrong.Now, for something like a dedicated miner for 5/6xxx you'd "only" have to handcraft a kernel for each arch in VLIWx ASM (fully documented in public AMD docs btw) and hack the radeon driver so it allocates input/output regions and loads/runs your shader program on command. Iirc there's still a open 200BTC bounty for a miner working like that. but it's a *lot* of work for very little benefit. 1-upd!max @ stock V: 1070 core, 695Mh/s@ 1.20V: 1170, 759Mh/sand for shits and giggles...@ 1.25V: 1240 core, 805Mh/sTip: try phoenix with -k poclbm AGGRESSION=10 WORKSIZE=256 Err, what?Take a look at the Xorg radeon driver and how it does several parts of 2D acceleration on 5xxx and 69xx 
Won't get any disagreement from me, lazy coin creator is lazy... but hey, at least he fixed it when I pointed it out to him.  *checks commit log*Default transaction fee was increased from 0.0005/kB to 0.1/kB.Seems to still use standard BTC rules for which tx don't require a fee.See LTC TX spam fiasco for the reason. *facepalm*Again, completely avoiding the topic of outrageous claims without *any* proof.Oh wait, the "proof" is writing a miner that's 20% slower than poolers. right.Ignored. Reference C implementation slower than optimized asm, news at 11.So... exactly what pooler did, except he managed it without big secrecy or talking about boolean simplification and factor 1000 speedups "if it only had worked".Tip: Statements like that make me think "oh dear, another crypto kook". ... says the guy claiming +1024 is negative. Let's play a game of counting XORs, shall we?Code:for (i=0; i<32768; i+=16){ for (j=0; j<16; j++)  uiStorage[i+32+j]=uiStorage[i+j]^uiStorage[i+16+j]; Salsa(&uiStorage[i+32]);}for (i=0; i<32768; i+=32){ for (j=0; j<16; j++)  uiStorage[i+j]^=uiStorage[i+16+j];}for (i=0; i<32768; i+=16){ j=((uiStorage[32784]&1023)<<5)+(i&31); for (k=0; k<16; k++)  uiStorage[32768+(i&31)+k]=uiStorage[32768+k]^uiStorage[32784+k]^uiStorage[j+k]; Salsa(&uiStorage[32768+(i&31)]);}first loop is 2048 times 1 16-dword XOR2nd loop 1024 times 1 16-dword XOR3rd loop 2048 times 2 16-dword XORs (sorry, a 3-input XOR is still 2 XORs)total # of 16-dword XORs ... 7168vs. a simple stupid scrypt(1024,1,1) (using 16-dword vectors for X and V to keep things more readable):Code:for (i = 0; i < 1024; i++) { V[i*2+0] = X[0]; V[i*2+1] = X[1]; X[0] ^= X[1]; X[0] = salsa20(X[0]); X[1] ^= X[0]; X[1] = salsa20(X[1]);}for (i = 0; i < 1024; i++) { j = X[1].vec_element[0] & 1023; X[0] ^= V[j * 2 + 0]; X[1] ^= V[j * 2 + 1]; X[0] ^= X[1] X[0] = salsa20(X[0]); X[1] ^= X[0]; X[1] = salsa20(X[1]);}let's count again...1st loop 1024 times 2 16-dword XORs2nd loop 1024 times 4 16-dword XORstotal # of 16-dword XORs ... 6144Congratulations. Your implementation *increased* the total # of 16-dword XORs vs. reference scrypt by 1024... ?!? I think so far everyone has been using true Vcore under load as AB beta10 displays, so set target 50-70mV higher. *6*870. Probably stock clocks or a suboptimal miner with a very mild OC.And 430Mh/s from 5850s? That's ~1GHz core. Wonder how long they'll last... Not really, more like ~0% stock and ~ +30% undervolted at stock clock vs. my old 5970 numbers here.Guess we'll never know why on earth AMD decided to go with 1.175V core at 925 MHz, so far all cards seem perfectly happy at 0.95-1.05V at 925 core for mining and 3D. While at stock V they seem to OC to 1050-1120 MHz... Now the big Q: if those aren't cherry-picked chips, what will 7990s be able to reach? your 2 unknown card idle wattages are A and B, your system is Xmeasure: (X + A), (X + B), (X + A + B)(X + A) + (X + B) - (X + A + B) = X(X + A + B) - (X + A) = A(X + A + B) - (X + B) = B X for the os + several MB per instance.So for several instances ... about X + several^2 - Y*several (where Y is shared libraries). Check the 3*7970 thread, you have to use MSI AB with unofficial overclocking set to 2 to be able to lower mem clock < bios limits, so far haven't found a way to do it on linux. :/ for some reason you have to manually load libXext before libatiadlxxCode:--- a/adl_api.py  2012-01-18 18:04:59.199777656 +0100+++ b/adl_api.py  2012-01-18 18:05:11.199734821 +0100@@ -36,6 +36,7 @@         from ctypes import RTLD_GLOBAL          # load the ADL 3.0 dso/dll+        CDLL("libXext.so", mode=RTLD_GLOBAL)         _libadl = CDLL("libatiadlxx.so", mode=RTLD_GLOBAL)              # ADL requires we pass an allocation function and handle freeing it ourselves ... yet the whole system only gets a measly 2.34Mh/J, why do I have the sneaking suspicion someones "idle" numbers are off? That's why I put that $60 via board there, cheapest board w/ cpu and a PCIe I could come up with quickly, atom boards w/ PCIe tend to be > $80 and any cheap AMx + sempron is also > $60.Btw, where do you find a AMx board w/ 7 PCIe slots for $80?And yes, I left out quite a few things. But start adding stuff like PSUs, materials/time for custom racks, PDUs, ventilation, ... and the whole thing gets overly complex. and the +$/slot ends up about the same. Well, let's see...$60 via board + $10 ram + $220 backplane for 7 cards. $41.43/slot$50 am3 board + $30 sempron + $10 ram + $10 extender + $220 backplane for 8 cards. $40.00/slot$80 am3 board + $30 sempron + $10 ram + $10 extender + $220 backplane for 10 cards. $35/slot (and lots of fun with 8 card driver limit)vs.$80 am3 board + $30 sempron + $10 ram + 2 $10 extenders for 4 cards. $35/slot.Meh. It is. And here's the X1250 (aka SS-1250XM) 80+ test report: http://www.plugloadsolutions.com/psu_reports/SEA%20SONIC_SS-1250XM_ECOS%202811_1250W_Report.pdf Nope, just factually correct info and helpful suggestions, presented in a professional fashion... Guess there's at least some hope remaining for this forum. For OPs mysterious shutdowns...X750 is single-rail, so can't be a problem there.Also, mainboard + stuff + one card on #1; 2 cards on #2 is the way to go.mysterious shutdown points towards #1 or mainboard having some issue (at least one piece of true info, you only get locked up cards if #2 drops out).Now for bad power causing issues... possible, my 4*5970 boxes regularly locked up or powered off on brownouts (got a line voltage monitor/logger, so correlation was easy).Another possible issue... southbridge chipset temp. msi 890fxa-gd70 is *very* iffy there.Oh ,and on that board the CPU voltage regulator phase switching is... problematic. Maybe test if the problem goes away if you disable it, or just keep the cpu at 100% load constantly (no fucking clue why that helps, but it did work here to stabilize a 890fxa w/ 4*5970 and a Athlon2 X2...).Now... long rant:So much misinformation in one thread.Quite a strong general statement there. Got any proof to back that up?For a group-regulated design, you want some load on +5/+3.3, due to obvious reasons, and those *can* fail if you don't do it.But for anything that uses DC/DCs to create 5V and 3.3V outputs ... no.And if you had bothered to check out the X750s OP is using... guess what... they *are* 12V + DC/DC based.Uhmmm... nope. No problem either.Please find *any* video card that connects the aux connectors together (violates PCIe spec. badly).Or hell, any card that doesn't like one of them at 12.6V with the other at 11.4V.Now why *isn't* that a big problem? Well, modern multiphase DC/DCs as used on any recent graphics card deal it pretty nicely, you get some uneven average current on phases powered from different voltages, roughly the same % mismatch as the voltage mismatch. Read up on theory of operation of synchronous multiphase step-down converters with current-mode control of individual phases and you'll figure out why.So... why on earth can't people stop to check their "facts" or even just think for a bit before regurgitating the same old myths and overgeneralizations? Well, at least on 7970 it seems not horribly memory limited.925 to 1125 = +21.6% core gives +17.1% performance (= 80% effective)even at 1125 core 1375 to 1575 memclock =+14.5% only gets ~ +2.5% performance (= ~18% effective)That looks a lot more core than memory limited to me.So if it's *supposed* to be mem limited... that kernel still has lots of room for improvements on 79xx.
ubuntu natty amd64, kernel 2.6.38-13-generic, xorg 7.6, built fglrx 11.12 debs from ati package with --buildpkg by big fat overlay I mean you constantly have a greenish-transparent text in the bottom right screen corner that says "Unsupported Device"xorg.conf is just your basic ati xorg.conf, haven't bothered trying to get multihead support working in linux on that boxCode:Section "ServerLayout"        Identifier     "aticonfig Layout"        Screen      0  "aticonfig-Screen[0]-0" 0 0EndSectionSection "Module"EndSectionSection "Monitor"        Identifier   "aticonfig-Monitor[0]-0"        Option      "VendorName" "ATI Proprietary Driver"        Option      "ModelName" "Generic Autodetecting Monitor"        Option      "DPMS" "true"EndSectionSection "Device"        Identifier  "aticonfig-Device[0]-0"        Driver      "fglrx"        BusID       "PCI:1:0:0"EndSectionSection "Screen"        Identifier "aticonfig-Screen[0]-0"        Device     "aticonfig-Device[0]-0"        Monitor    "aticonfig-Monitor[0]-0"        DefaultDepth     24        SubSection "Display"                Viewport   0 0                Depth     24        EndSubSectionEndSection Old corsair 550W? What model exactly?If it's a VX it *should* work fine at least for a while, just follow the usual guidelines (underclock GPU ram if possible, make sure everything gets enough fresh air, don't start overvolting GPUs with a wimpy PSU, ...). Might last for years, might decide to go tits-up after a few months at continuous high load. Appeal to authority.Also, *all* psus have an efficiency curve. By definition. what moron would claim otherwise?Server PSUs? Nope. They usually peak at about 70% load, partly because they're underrated to increase reliability, partly because servers statistically spend more % of time at high utilization = load.SFF PSUs? nope again, generally at 50-60% load, some a bit lower, some a bit higher.Link? Efficiency curves for all real 80+ units are freely available from ecova, so finding a few examples should be trivial, right?And... err... yes, a PSU being labeled "Active PFC" usually means it has... active PFC. Nothing else. Duh.So PLEASE inform yourself before making up claims in the name of some "IT director" k? 1. That blog post is from 2007. The review it gets its data for the 480 from is from 2004.2. Checked what site reviewed that Antec 480... and when? Starting to see a link here?3. Who the FUCK graphs efficiency vs. *input* power? Doubt it, basically all I did was disable the ati-specific tweaks, replaced the BFI_INT parts with bitselect() and set fixed work group sizes (16x16 for first and 3rd kernel, 64 for 2nd) linux, cat 11.12, sdk2.6, vanitygen git, disabled BFI_INT to get correct results925/1375 28.1Mk/s1125/1375 32.4Mk/s1125/1575 33.2Mk/s1170/1600 34.1Mk/ssome more testing, disabled EXPENSIVE_BRANCHES and DEEP_VLIW, -g 2048x2048 -b 256925/1375 37.1Mk/s1125/1375 43.0Mk/s1125/1575 43.7Mk/s1170/1600 45.0Mk/smore tweaking...925/1375 39.8Mk/s1125/1375 46.6Mk/s1170/1600 49.1Mk/sedit: 50.1Mk/s at 1200/1600 with 11.12 (and the 12.1 in the ocl1.2 dev preview) aticonfig doesn't recognize it.manually edit xorg.conf and the card works (with a fat "unsupported device" overlay).atitweak can be used to check temp/set clocks/set fanspeed/...diablo and phoenix work.edit: "device 6798" = your lspci doesn't have it in it's database yet and shows the hex PCI device ID. same here. *looks into crystal ball* a bit over 1Gh/s at a bit over 250W with memory underclocked, ~300W at stock mem clock.Bump core voltage to 7970 levels, memory to min clock, core clock to well >1.1GHz and you're probably looking at >1.3Gh/s at ~400W.Compared to $299 5970s it obviously loses massively for price/perf, but supplies of those are drying up.Compared to $699 6990s, even at $899 it looks like a clear winner; higher density, higher efficiency, better price/perf.And likely far greater % of retained resale value. 160W lower idle. Replace heavily overvolted OCed PhenomII with undervolted AthlonII or Sempron and you're mostly there. What? That's Chinese high quality assembly! On a more serious note, as long as the solder joint is ok a electrolytic cap sitting a bit crooked won't affect anything other than looks. VERY bad/dangerous idea, see https://bitcointalk.org/index.php?topic=44495.0 as for why. Seems like a waste of time to maintain it, if people really want to cpu mine they can just use one of the available dedicated cpu miners or deal with maintaining a fork of cg. Basically... nope. Marginal riser cables don't cause hashrate fluctuations, they do cause hard lockups and/or cards sometimes not getting recognized on boot.On a similar note marginal power doesn't cause hashrate fluctuations either, it causes hard lockups and crashes.What os/driver/sdk/miner combo? *grabs crystal ball* I see a nonreference sapphire or xfx.Ref card fans last pretty close to forever even at 100%, unless you got one with a production defect (those tend to start rattling after a few days and are dead within weeks at pretty much any %). No graphics card I know of does that, it's also a massive no-no according to PCIe spec.Simple reason, defeats per-rail overcurrent protection -> fire hazard.Not to mention the havoc that could cause with PSUs that have 12V rails coming from 2 independently regulated 12V supplies (not too uncommon in >1kW units nowadays).Too lazy to dig up the exact text, but basically you're forbidden from creating a galvanic connection between each 12V aux connector and 12V from slot.Also cards have to accept any power sequencing of 12V for any amount of time without sustaining damage.They're not required to function if time from first to last 12V input coming up is > 100ms or if any input drops out after the initial 100ms.But so far all cards I've seen seem perfectly happy with aux 12V coming up long before slot and staying on while slot 12V goes away and comes back (= aux supplied from 2nd always-on PSU). Leakage current is highly temperature dependent, and a good chunk of total power consumption for sub-45nm bulk CMOS processes.Switching speed is inversely related to temperature -> you can reduce operating voltage to "compensate" the speed gain, thus reduce dynamic and static power some more.So yes, improved cooling can lower power consumption by a noticeable amount; No clue how much it is at 28nm, but I wouldn't be surprised if it's > 10W for 70 vs. 40 °C on these. The "internal" grounds are already pretty damn well connected.1. On ATX PSUs, secondary GND is directly tied to safety ground, otherwise it'd be illegal to sell in most of the civilized world. Don't believe me? Just measure it.2. Graphics cards have all PCIe power connector and card edge connector grounds tied into a massive ground plane. Again, if in doubt, measure it... use a 4-wire mOhm meter or you'll only be seeing 0.0 So, where does the "you have to tie grounds together" myth come from?Simple.Basically you need the following scenario:1. Building with improper/unusual wiring and several V difference between safety ground potential between "close" outlets.2. 2 PSUs that are *not* electrically connected via a common metal chassis (if both are screwed to the same steel chassis, that's usually a low enough resistance path to reduce the potential difference to safe levels of a few dozen mV).3. said PSUs being plugged into said outlets. Now we have 2 PSUs where #1s GND is a few V different from #2s GND.4. One connected to mainboard, another connected only to drives or similar. Now we have mainboard GND and drive GND differ by a few V...5. Data cable from mainboard to drive has ground/shield wires (duh). Now you have grounds differing by several V connected with a few strands of AWG26, smell the PVC? Worse... if data lines make connection first, (relatively) large currents flow through the I/O pin protection diodes, usually resulting in dead controllers and/or drives.In *that* scenario, connecting the grounds via a few AWG18 jumpers or similar reduces the potential difference between grounds to a safe level.So short version... if it makes you feel good, tie secondary grounds together all you want, but it's flat out pointless if you're powering GPUs. Actually the problem comes from 2+ programs trying to bitbang the internal power management I2C bus simultaneously via direct GPU register access.The resulting corrupted I2C transactions have a good chance of writing 0xFFs to random registers, on a vt1165 that results in setting ~2.03V core;A hardwired limit in the vt1165 caps that to 1.65V.Fix is simple: don't run multiple programs that try to directly talk to the VRM controller at the same time. Yep, at current prices 7970 = really bad value for a mining card.... 800Mh from a 5970? In my experience the average 5970 gets about 820-840MHz core at stock V -> about 365-380Mh/s/core.With one 80+ gold and one 80+ bronze 1kW PSU, my quad rigs were ~1240W at the plug, with 2 80+ gold units a hair under 1200W.At 1125mV core and again clocked to max stable... slightly north of 810Mh/card average, while hash/J went from 2.57 to 2.32 and primary GPU VDDC slaves got uncomfortably hot.Imo if you got the space, 5850 stays king. High hash/$, decent hash/J, low enough power density to make cooling a relatively minor issue.That said, I'll be getting a 7970 anyways. Why? SHINY! 
<offended>Who the hell is calling me a whitehat?</offended>On a more serious note, if you're going to put a hat on me, it'd be some shade of grey, but sure as fuck not white.Broke GG1 (orphaning other miners + timewarp to drive difficulty to minimum) and "broke" SC1 (53 or so oversized tx bloating the chain and slowing things down, inadvertently triggered a bug/lack-of-optimization inherited from bitcoin that crashed a few nodes by consuming ~4GB of diskspace).While were at it, also found a node-crashing bug in bitcoins script interpreter in late '10 and crashed all testnet nodes.As for the accusations of me attacking I0C ... no clue where those come from.I0C broke because the joker who originally modified the retargeting fucked it up, and it flat out stopped working after 2 weeks.Then a patch from me fixed it (well... "fixed"... just ripped out the broken mess and replaced it with a modified SC1 retargeting).Long after it got relaunched and everyone lost interest in it again, bitparking i0c exchange got hit with a doublespend, but that wasn't me.I don't think anyone clearly admitted to that, iirc BEX hinted at having something to do with it... wouldn't be too sure, he also bragged about several other things I know are not true.So in case you haven't noticed yet, I tend to break things for fun, not profit  Well, Gavin already replied and stated his personal opinion, and any other bitcoin devs with half a brain will keep mum and stay out of this whole mess (hint: they probably don't give a flying fuck).So... thread done? Yep, another case of not understanding how bitcoin works.I've watched people come up with the same or similar bullshit "attacks" several dozen times in the last 18 months.I'm pretty sure there's even a FAQ entry for it on the wiki.But hey, you don't have to trust anyone, just read the whitepaper, read the source code, think for a bit, if you still don't believe it *try it*... and please post after you realize how clueless you've made yourself look. Anyone with a copy of the CLC blockchain and bitcoin-utils can easily verify that the bitcoin parent blocks used to attack CLC belong to eligius. Personal equipment my ass. 100% agreed.If your system relies on a lack of assholes on the internet... good luck.Btw, the same problem also exists for non-mergemined chains with miniscule hashrate right after launch, remember the massive FBX orphaning?Anyone with a dozen decent CPUs could do it... and someone did it. whoops. Except no one stepped forward admitting to the attack, so instead of 20 pages of forum drama spread over a dozen threads we got a bunch of "aww, sucks" posts and people moved on. Well... yeah. If you happen to find a ATX psu that's just barely within spec, it's outside of the nominal supply range of a S6. By 15mV.ATX spec also requires a 1A min load on each of 3.3V, 5V and 12V, so below that regulation can be bad (a real problem with group-regulated PSU designs).With modern high-efficiency psus generating their 5V and 3.3V with step-downs that issue seems to have pretty much vanished, some mV ripple at a few 100kHz+harmonics, nice and well behaved load step response even down to 0 load.As for seeing nasties on a 'scope ... are you measuring on a unloaded/unterminated line? Try with 10uF || 330R, or you'll be mostly measuring weakly coupled interference, transmission line effects/line resonating with your probe capacitance.But then I've only closely looked at 2 zippy and 2 superflower units, all of em 80+ gold or better and all of them good enough that I decided the added cost+complexity of a 3.3V step-down for each 8*LX150 board wasn't worth it.Had more issues with vccint droop, on my boards a 3-phase DC/DC was at one end of a 190x85mm board... close to a 50mV drop to the furthest pair of LX150s. Salvaged by adjusting the converter up to 1230mV and adding lots of jumpers. rev1.1 moved the converter to the center of the board and rev2 changed the board geometry completely (2 rows of 4 instead of 4 rows of 2). Tight coupling between UI and core (somewhat reduced with 0.5), Horrible OO design in parts, data members being public in lots of places instead of having accessors, sometimes outright WTF-worthy approaches to doing things. I wouldn't say incompetent, just lazy/messy. I don't get what the huge outrage is about.Author of FOSS miner offers to work on improved 7970 kernel if he gets enough donations towards buying a 7970.That's pretty much the same way you get your personal pet hardware supported by FOSS firmware. Guess next you'll be boycotting dd-wrt and the likes. ... says who? According to spec it should work fine, and reality over here agrees. 54 S6s happily running with vccio and vccaux fed from atx3.3. In case you're wondering why the SSE2 version sucks on K8 and K10 ... reason is rather simple.the salsa20 function is a long string of data dependent 4*32-bit vector integer operations (i.e. output of one operation is used as input to the next).And the execution latencies for the most used instructions in the salsa20 core (shift r/l immediate, add, xor) are all 2 clocks on K8/K10, all 1 clock on Atom/Core/Core2/Nehalem/SB.End result ... sse2 salsa20 needs roughly twice the clocks/round on AMD compared to any modern intel. Well, it changes voltage for the wrong VID on 5970s by default, on 5970s (and iirc ref 5870s) VID 3 is for performance mode, on ref 5850s it's VID 2. Yup, sure looks like a used card.That TIM on the GPUs isn't original; all ref 5970s I pulled the fansink off of had phase-change pads, not goop.Also, good idea with the dead phase. Check VRM temps under load, if one of the 3 phases is a lot (20C+) cooler than the others you got a dead phase; the card will generally still run but unstable and OC like crap.If that's not the case... idiot who replaced the GPU TIM didn't replace the thermal pads for the VRMs. Most important ones are the one for the core VRMs. the long one under the fan and the smaller of the strips above the vapor chamber. inductor, ram and pcie bridge pads aren't really that important. Used a bunch of a 1mm sheet of 3M 5591 I had lying around. worked like a charm.In linux a slightly modified radeonvolt works for reading VRM temps and overvolting 5970s.As for the holes in the paste... bet the monkey who applied the paste touched the die and didn't degrease it before applying new paste. that generally ends up looking *exactly* like this. Hard to tell from pics, but ferric oxides (aka rust) def. can cause such a brownish tint.Steel dust from grinding would be a good source. Did you have the loop open while you were dremeling the case? If you don't have a irrational phobia of mating Sn and Au plated surfaces, 45750-1112 should be the right one. I used 45750-1212 - same thing, just gold plated and like 5 times more expensive. Enigma81: You sure?13A is only when loaded with mini-fit HCS contacts, which is only required by the spec for PCIe 8-pin connectors (and possibly EPS 8-pin, too lazy to check), but normal atx 20/24 pin doesn't require em.So we have normal mini-fit contacts, wire-to-board, for AWG16 or AWG18 wire, brass contacts are rated for 9A, bronze contacts 8A. derated down to 6A repective 5A depending on # of loaded circuits in housing, board layout, ... (read the fine spec sheet for the contacts, it's freely available from molex).And that's assuming those are real mini-fit contacts, and not some cheap sub-spec lookalike... fat chance.As for desoldering coarse stuff, *love* my Weller DS100.Back on topic.Burnt the 12Vs on a atx 24-pin running quad 5970s on a MSI 790FX-GD70. Replaced the connector on the board and the plug housing, replaced the 12V contacts with mini-fit HCS series. Preemptively replaced the 2 12V contacts in 5 identical other boxes (one had the plug already partially melted around one pin). No further burnt 12V lines operating 24/7 for over 6 months.Other stuff:Dead fans (both the well-known bearing failure) on 2 reference 5970 coolers.4 Sapphire nonref 5770s with dead fans.>20 Sapphire xtreme 5850s with dead fans.Fried the VRMs of the 2ndary GPU on 2 5970s with AC Accelero coolers.Coolermaster 650W 80+ bronze blew up running 5970+2*5770 (12V output filter coil burnt).3 Andyson-based 1kW 80+ gold PSUs blew up, each running only 3 5970s at ~880W at the plug (secondary side synchronous rectifier FETs failed).Box full of dead Scythe UK3K 120x120x38 mm fans, all bearing failure. Replaced with deltas... buy cheap, buy twice. and 370 / 905 * 940 = . Oh. Same as bitcoin, difficulty 1 = about 2**32 hashes average per block. Not sure on power, someone bored enough to synthesize a design and run power estimations?Don't get fooled by xilinx S6 perf/power, those are the worst of all 45/40nm FPGAs by a long shot; we pretty much only use them because they're cheap-ish and readily available in small qty. Those packages look like 1mm grid thermally enhanced flipchip BGA ... guesstimating by the 0.1" headers ... 29x29mm FF780so if these are SIII, pretty much "could be anything from a L50 to a E260"One thing kinda throwing me off... if those are HCs, 1.1V core doesn't make sense. HCII is 1.2V and HCIII and IV are 0.9V.As for "what SIII would you need for that"... depends on how much time you spend optimizing, first guess would be 2 unrolled engines with 1 pipeline stage per round, each running @ 250MHz... gut feeling says a L150.So, random guesses:a) these are HCIIIs, they prototyped with SIII and forgot to update the label for vcore.orb) only SIII based prototypes exist, once they get enough pre-orders HCIIIs get ordered (about 8wk if you rush assembly... possible.)orc) they somehow got a whole bunch of large SIIIs really cheap.ord) something entirely different. ngzhang: Altera SIII is 1.1V core.
Nope, hardcopy is a "real" sASIC, I think you're thinking of xilinx easypath (which is pretty much maskROM programmed FPGA).And I never quite said that sASIC isn't competitive, I said the specific device I used was barely competitive with 45nm FPGAs. Mainly thanks to having no dedicated adder resources and being older (but also low up-front cost) technology.If this is based on something like a 40nm hardcopy III, performance and power figures look like they're in the right ballpark. Yes, looks like about 10% of blocks still contain spam.0.5.0.8 only ignores spendable outputs < mininput for sending, so if you're at the receiving end of dust it still shows up in listtransactions and friends and causes increased memory use (current bitcoind and forks keep all wallet tx in memory).If you want to try, http://pastie.org/2909400 is a band-aid to make the wallet ignore new incoming tx that only contain outputs to you < mininput. If you really want the dust later just set -mininput 0.00000001 and do a -rescan. apt-get install libdb4.8++-dev (or 4.7 or 5.1 or whatever you want) 10000 at once is too much.Assuming your inputs are block rewards (7 GG each), you're trying to create a transaction with 1429 inputs.each input is ~230 bytes -> that'd be a ~330kB tx.Stock client refuses to create transactions > 100kB.So if all you have are generations, either do 3000GG or less at a time, or if it has to be a single tx send to yourself first to consolidate your generations into a few bigger outputs. http://allchains.info/ Changing the blockchain math seems a lot more elegant than setting the genesis timestamp to 3 years ago and premining 300k blocks, requiring everyone to download and store 65MB of completely superfluous data. You know, it'd be simpler if you posted bug reports in easier to find places. This happens with low --scantime and is inherited from upstream cpuminer.This commit should fix it: https://github.com/ArtForz/cpuminer/commit/99084f8be4de50789345c42ae1e56378496c2981 You're trying to build the gui client, for the daemon... make bitcoindand the bitcoin wx gui always needed wx 2.9 ... Yup, on a recent debian/ubuntu just installing one of the libcurl4-*-dev packages should be enough. Sad to hear that, as the current HEAD also improves speeds for K10 even when compiled with older gcc versions to near gcc-4.6.1 levelsGuess this one will have to stay in non-official state for now (looks like it also produces rather crap asm when compiled for 32 bit targets...). What release? The releases are done by Lolcust, I only keep a git at https://github.com/ArtForz/cpuminer Shrug, don't care much.But this is interesting:So Mr. "Professional Developer" has a hobby of stalking perceived "enemies" on the internet and boasting about it... *facepalm* Well, technically 7 million is less than one hundred thousand thousand.But yeah, I agree. the 7.7mil superfund should be laundry-only to prevent abuse. When you have no product to show and no arguments, try some good old mudslinging.That's totally the behavior you'd expect from a "professional developer" with "decades of experience creating commercial software", not some 22yo aspie with a superiority complex living in his moms basement, right?See, easy! I've run 3*5970 on this exact board, so > 4 GPUs does work.Yep, PSU is a possiblility, there's 2 current Rosewill 1kW units:RBR-1000M = Andyson OEM. Had half a dozen 1kW PSUs based on the same Andyson platform crap out after ~3 months while only running dual 5970s.LIGHTNING-1000 = SuperFlower OEM. Seems pretty good, so far had zero of those die, and thats with 2*5970+2*5770 or 3*5970 on em.Anything older... not sure, probably not too good. lightlord:Of course it's possible to implement on a GPU, why wouldn't it? See https://bitcointalk.org/index.php?topic=45849.0 for what I managed to get out of a HD6970.Matthew N. Wright:If you got no clue, STFU. True. Just wondering how "fun" handling this on reorgs will be.Thats why I went with the "start with the stupidest possible implementation, optimize later" assumption  Sounds like a damn great idea.I agree the KISS version should be relatively easy to implement, but I suspect it'll become dog-slow if the laundry ever becomes popular.Basically, if a tx input is spending a output belonging to one of the 2 laundry addresses, sum up *all* unspent outputs of those 2 and consider the tx invalid if spending that output would bring the total below the threshold.The problem is when the deposit buffer fills up with 10000s of tx... that scan-and-sum needs caching. Not sure what's going on there (aka "can't reproduce issue").My only guess is it's possibly related to removing the sha256 algos, but... that was even before I started doing the compilers job for scrypt.Not sure what to do other than general hints along the lines of "start with a clean tree, CFLAGS="-whatever" ./configure; make"Hrrrm... I guess you could revert the sha256 removal or drop the new scrypt.c into Tenebrix-miner and see if that also causes the same issues. Just pushed another small tweak, gets another 3% or so on K10s.
Nope, haven't played with nv yet, and certainly not with teslas.But looking at the spec and architecture...14 CUs with 64kB L1/LDS per CU and 768kB global cache (128k per 64-bit memory controller). 32 ALUs/CU, clocked at 1.15GHz6970 = 24 CUs with 64kB L1/LDS per CU and 512kB global cache. 64 ALUs/CU, clocked at 880MHznv L1 can do 2 reads/clock, so... wild-ass guess... might end up at 30kH/s or so.Of course the lack of a native rotate won't exactly help, scrypt is sha256 (we know that one...) and salsa20, in which *every 2nd op* is a rotate.so... probably more like 20kH/s. Probably because these "issues" aren't issues unless you have a ancient P4 or something.My PhenomII is happily hashing along at 20kHps while increasing system power usage at the wall by 108W.2^32 * 0.0926 / 20000 / 3600 ... about 5.5h/blockso ~108tbx/day for 2.6kWh/day*checks btc-e* 108tbx = about 0.83 btc less fees, let's say 0.8at 4.82/btc ... $3.85/day less power... about $3.20Yeah, can't see why people are throwing as many CPUs as they can find at it... CFLAGS="-whatever -somethingelse" ./configuremake clean; makeor just edit the CFLAGS= line in makefile after configuringI like to always make clean so there's no objs from previous compilations with different flags hanging around  Just pushed some more scrypt manglery, 3.62kH/s/core with -march=amdfam10 -O3 That's a problem inherited from cpuminer, some distros *cough*redhat*cough* don't package libcurl.m4 in curl-dev which causes exactly this :/You can easily get around it by commenting these lines out though, since pretty much everyone with linux is running curl already[/quote]model name   : AMD Phenom(tm) II X6 1100T Processorcpu MHz      : 3600.000gcc -vgcc version 4.6.1 (Debian 4.6.1-13)uname -aLinux buildhost 3.0.0-1-amd64 #1 SMP Tue Sep 20 07:03:13 UTC 2011 x86_64 GNU/LinuxCode:./configuremake./minerd --userpass artforz.1:1 --url http://pool.simplecoin.us:8337/ --threads 5[2011-10-05 20:48:59] Long-polling activated for http://pool.simplecoin.us:8337/LP[2011-10-05 20:49:03] 5 miner threads started, using SHA256 'scrypt' algorithm.[2011-10-05 20:49:22] thread 0: 63077 hashes, 2.67 khash/sec[2011-10-05 20:49:23] PROOF OF WORK RESULT: true (yay!!!)[2011-10-05 20:49:24] thread 1: 65535 hashes, 2.67 khash/sec[2011-10-05 20:49:25] thread 2: 65535 hashes, 2.67 khash/sec[2011-10-05 20:49:26] thread 3: 65535 hashes, 2.66 khash/sec[2011-10-05 20:49:27] thread 4: 65535 hashes, 2.67 khash/secCode:CFLAGS="-O3" ./configuremake clean; make./minerd --userpass artforz.1:1 --url http://pool.simplecoin.us:8337/ --threads 5[2011-10-05 20:50:11] Long-polling activated for http://pool.simplecoin.us:8337/LP[2011-10-05 20:50:16] 5 miner threads started, using SHA256 'scrypt' algorithm.[2011-10-05 20:50:32] thread 0: 65535 hashes, 3.21 khash/sec[2011-10-05 20:50:33] thread 1: 65535 hashes, 3.23 khash/sec[2011-10-05 20:50:33] thread 2: 65535 hashes, 3.24 khash/sec[2011-10-05 20:50:34] thread 3: 65535 hashes, 3.24 khash/sec[2011-10-05 20:50:36] thread 4: 65535 hashes, 3.22 khash/secCode:CFLAGS="-march=amdfam10 -O3" ./configuremake clean; make./minerd --userpass artforz.1:1 --url http://pool.simplecoin.us:8337/ --threads 5[2011-10-05 20:51:22] Long-polling activated for http://pool.simplecoin.us:8337/LP[2011-10-05 20:51:26] 5 miner threads started, using SHA256 'scrypt' algorithm.[2011-10-05 20:51:42] thread 0: 65535 hashes, 3.27 khash/sec[2011-10-05 20:51:42] thread 1: 65535 hashes, 3.27 khash/sec[2011-10-05 20:51:43] thread 2: 65535 hashes, 3.27 khash/sec[2011-10-05 20:51:44] thread 3: 65535 hashes, 3.28 khash/sec[2011-10-05 20:51:45] thread 4: 65535 hashes, 3.29 khash/sec If you're on amd64 linux, might wanna try my mangled scrypt cpuminer: https://github.com/ArtForz/cpuminercompiled with CFLAGS=-O33.28 kh/s/core on a 3.6GHz PhenomII2.73 kh/s/core on a 3GHz AthlonII2.40 kh/s/core on a 2.7GHz Sempron 140 Another tiny problem, all nonparallelizable puzzle schemes proposed so far require the puzzle creator to keep a secret from the puzzle solver. How exactly do you do that in a decentralized system? Dunno, it's still plenty profitable around here, and that's at $0.30/kWh...Unless you have a P4 or pay like $1/kWh ... how on earth do you end up with a loss? So.. it went from "pretty much nothing" to "3 times pretty much nothing"?There's only 300k in existence so the "bullshit index" of total coinage (brixage?) times current trading price went from 50 to 150 btc... That also shouldnt become a major issue, merely the current implementation scaling badly there.To increment the extraNonce in the coinbase transaction, we rehash every transaction in the block and rebuild the whole merkle tree, so the whole thing ends up scaling with (blocksize * requestrate). Adding the obvious optimization of storing the opposite side for the merkle branch and only rehashing coinbase and its merkle branch, we need an additional (log2(#tx in block) * 32) bytes of memory but scale roughly with (log2(#tx in block) * requestrate) for getwork.At something like a current average block (~10kB in ~20 transactions), that comes out to ~240 vs. 8 sha 256 operations for 4Ghps worth of work.Scaling to visa-level 10 kTX/sec (that'd be 3GB blocks containing ~6M transactions ...), it's ... about 50 sha256 operations for 4Ghps worth of work.So for a pool roughly the size of the current network that'd be... for current tx volume 24k sha256/sec vs 150k sha256/sec for 10k tx/s.And using something like "miners increment block time themselves", this can be cut down by another factor of 60.Scaling this for increasing hashrates due to Moore's law... well... that applies to both sides.So for the getwork+PoW side, I just don't see any hard issues coming up.I expect to see way bigger problems on the transaction handling side of things scaling to such massive levels, assuming every tx has 2 inputs + outputs on average, you'd be verifying about 20k ECDSA sigs/second and on every block you're marking ~12M outputs as spent and storing ~12M new outputs in some kind of transactional fashion, probably just the list of current unspent outputs would be on the order of 10s of GB ... ugh. Currently 76 bytes? Not using the getwork protocol. A getwork response without http headers is already close to 600 bytes... to transfer 76 bytes of data.But yes, optimally it'd be 76 bytes (+ a simple header).There'd be ways to cut that down even more, version is constant, nBits only changes every 2016 blocks, hashPrevBlock only changes on a new block, why send those every time?Another option, allow miners to update nTime themselves.work submits could be cut down in pretty much the same way, requiring only hMerkleRoot, nTime and nNonce. If there's too many increasing share difficulty would be trivial.So, a simple more efficent protocol would have per 4Ghps:hMerkleroot + nTime every 60 seconds or whatever the tx update interval is, hPrevblock every 10 minutes avg.hMerkleroot + nTime + nNonce every secondat 100% efficiency, diff 1 shares and with some overhead that comes out to around 1 byte/second avg send and 45 byte/second or so avg receive for a poolserver for 4Ghps of miners.Or about 24kbit/s send and 1Mbit/s receive for a pool the size of the whole current bitcoin network. Yeah.If hashrates increase in the future, increase share difficulty by a few powers of 2 and you cut down the incoming rate accordingly...So for the pool-miner interface, you can scale it up quite a few orders of magnitude before bandwidth becomes an issue.For the network side, scaling to transaction volumes that are allowed by the current max network rule of 1MB/block, we need to receive and send the tx in that block and the block itself, that comes out to... 53kbit/s average.The 1MB block size limit should be enough to fit about 4 tx/second average.So... your average home DSL will become a problem when scaling up more than an order or magnitude above the current limits, we'd *need* some kind of hub-leaf setup beyond that, and assuming the hubs are decent servers you could easily get another 2-3 orders of magnitude. ... which would be roughly on par with visas peak tx capacity levels...So doesn't look like bandwidth would become a major issue. Back of the envelope based on last 100 blocks ... network is about 1900kH/sThat's ~100 or so high end CPUs or somewhere around 2000 old/slow ones...= Still way too small to be more than a small speedbump for an attacker willing to shell out some $ for EC2 instances or with access to even a "tiny" botnet.The problem with a "typical" CPU ... no such thing.8-core Opteron or modern high-end Xeon > 20kHps, your average old P4 space heater ~ 1kHps... while using about the same amount of power.CPUs tend to follow Koomey's law (which roughly says power efficiency doubles every ~15 months). This is getting OT, but judging by the currently seen client versions on the network you'd probably need a prewarning/transitional period measured in years to have a good chance at all old clients upgrading in time...Back on the original topic, ran some sims, doesn't look like there's a hard point where a faster difficulty adjustment using the original integrator becomes unstable (short of going to extremes so it slams into the limits from normal fluctuations in hashrate), "merely" makes difficulty adjustment more noisy. Near identical results with a sliding window and scaled factors (looks smoother, but pretty much the same deviation from optimal (as expected)).For a interesting practical experiment in "just how short can you make the window and how extreme the adjustment", look at GeistGeld chain (retarget every 16 blocks, adjustment limit roughly * / 1.8. that comes out to a adjustment limit of */ somewhere around 1e30 over 2016 blocks). Somewhat surprisingly it more-or-less works so far... Thats the weird thing, currently it'd be way more profitable to cpu-mine tbx than btc, yet no decent botnet in sight.At current btc/tbx difficulty ratio, a botnet cpu-mining tbx instead of cpu-mining btc "loses" somewhere about 0.00005 btc/tbxEyeballed scale factor... cpus are about 1000 times faster at btc hashing than tbx hashing...tbxdiff / btcdiff * roughhashscalefactor * blockrewardfactor0.042 / 1.69M * 1000 * 2 ... around 0.00005*checks* btc-e ... best bid: 0.00158btc/tbx.so only like 30 times more profitable to cpu-mine tbx currently... Wrong, it's a forward-and-backward-incompatible change, as at the first retarget 2015 and 2016 have a good chance on disagreeing what the next target should be. Namebrix?  Yup, 128KiB, which goes for the "small enough to easily fit in L2, big enough to not be able to fit more than a few instances in a GPUs on-chip memory/caches" point.If I could change the parameters again I'd probably add more margin and go for scrypt(4096,2,1) = 1MB of randomly-accessed-array per instance.Still small enough to mostly hit L2 on a CPU, but even on future GPUs with several MB of fast on-chip cache/store you could only fit a few instances.Should do about 300 hash/s on a high end cpu core, at least 50 or so on a crappy one, so it'd be barely fast enough to not hinder block verification *too* much (you'd have to add some protection to avoid having your node spammed with bullshit blocks, but nothing too fancy).It'd also pretty much eliminate Cell as a contender (SPEs local memory is 256KiB...) and completely eliminate low end FPGAs (LX150 only has ~ 512KiB total block ram, and external memory is *way* too slow to make sense).Going for L3 or external memory is imo a bad idea in this case as that's a shared resource = running a miner on even one core pretty much kills memory subsystem performance. Didn't think of that, if the avg hashrate fits it'd be a "duh" case. Also "decently cheap" to pull off. *and* it would explain why he scaled down after block 2016 and completely stopped after 4032. Contemplating this some more... the "pure fork" part had ~4.2s/block, average nonce was ~235k, unless I'm missing something and assuming cpuminers algo for nonce generation, average hashrate/box should be simply avg nonce / avg time ... that'd come out to about 55kH/s/box...  need to do a test to see if this assumptions holds, if yes it looks closer to 4-5 high end quad-cpu boxes. At least that'd be a lot less "weird" than a single cpuminer instance running on like 80 cores.edit: nope, stock cpuminer, tbx-miner and my cpuminer fork keep one workitem *per worker thread*, so those nonce values would mean someone was running 4-5 *threads* at about 55kH/s each... very odd.Hmmm, or using a patch that does the "split single workitem into chunks of nonces to hand off to miner threads" thing, pretty sure there's already a fork of stock cpuminer doing just that and merging that with tbx-miner should be trivial.So with that scenario... our attacker has access to at least few beefy servers, some understanding of bitcoin, can apply patches and recompile. (iirc there's like a 3-line patch to bitcoin to implement a stupid "fork existing chain after block X" floating about on the forum somewhere...). Sounds like your run of the mill BOFH. *ducks* Well, relying on block timestamps seems somewhat pointless, there's no reason the attacker couldn't fake the timestamps in his forkblocks to be "close enough" to the real chain to leave no obvious gaps.So... how do you figure out which chain was "first"... if your node is live at the time it's pretty easy, but what if it was off for a while and when it gets back there's now 2 similar-length chains? Solving the 51% problem in the general case without creating single points of failure or new vectors to mislead nodes is ... hard.
Well, the most recent 100 fbx blocks took ~63 sec average at diff 0.00390625, that's about 266kH/s. so someone with a bit more hashrate than our forker could pull pretty much the same stunt even now.Any relaunch would start with way less miners on it, so it could potentially be fucked with the same way by the same guy(s), unless it's *started* with well > 250kH/s, or block acceptance rules are changed to make orphaning a existing decently-length chain a lot harder (did anyone ever do this? it'd make giving a fresh node a "fake" chain a lot easier, as in that case the main chain has to be the one with a lot more work than the fake one. But it'd also mean a rogue miner would need to have several times (3? 4?) the network hashrate to pull off a "fork the chain".I'm imagining something simple along the lines of "only accept a new block as the best if it's a direct descendant of the current best block, or if it's total work since the last common ancestor with the current "best" chain is 2 (3? 4?) times higher than the work done in the current best since that common ancestor." *could* work.It'd also mean network efficency would drop, as miners happening to mine a orphan would get stuck mining completely pointless children of it until the main  chain got ahead at least 4 blocks... and if they're > 25% of total network hashrate, their client won't *ever* notice as their fork keeps growing fast enough so the main chain work-since-fork would never hits the 4-times reorg trigger limit. Well, back on topic then, picking apart my local fbx nodes blk0001, ... doesn't look very accidental.I have a 1327 block chain that was orphaned starting at block 58.There's a ~4h24m gap from block 57 to what now is the current block 58, and block timestamps after that look "reasonable enough" without huge gaps or long runs of minimum-time-increment blocks, so I'm guessing the attacker didn't fake block timestamps.By block timestamps, the orphaned chain was mined over 5h57m, the new chain spans 1h33m over the same block #s.taking hashes/time... the oprhaned original chain was mined at about 65kH/s, the same blocks in the new chain 250kH/s.And there's something decidedly odd about the block nonces in the new chain, they're ... too high.Orig chain had nonces averaging out to ~4000 (which is hinting at how many hashes one cpuminer instance is roughly doing between getworks...)New chain nonces average... about 235000so either a single cpuminer instance was doing ~60 times what your average cpu does, or they had something like a custom getwork proxy splitting workitems into noncranges and handing the same work with different starting nonces out to a whole bunch of machines (possibly to reduce getwork load?)but at "only" 250kH/s, why bother with that? pushpool can handle a few 100 mining boxes just fine.hrrrm... "single cpuminer instance doing 60 times your average hashrate" ... massive NUMA system? single system image cluster? My phenomII X6 @ 3.6GHz does ~3.25kH/s/core and new xeons are probably getting into similar ranges... 64-core server?Of course this is all pure speculation as I'm only assuming block timestamps weren't faked. If they were, there's no telling how much hashrate it really was.After that the "odd-noncey" blocks are still appearing for quite a while, noticeably drop off in count after 2016 and nearly completely stop after 4032, there's only 9 blocks with nonce > 100k but not obviously byteswapped after 4032.Thats another oddity, there's at least one other miner creating "weird" nonces, they're obviously doing em byteswapped (but appears slow-ish, only 32 of those byteswapped nonces in ~600 blocks since 4032).So overall... yeah, looks like someone with ~250kH/s deliberately orphaned blocks from 57 on to about 1400, then switched to mining legit and got about half of the remaining blocks up to 2016, slowed down for the next 2016 (looks like he went down to about 1-in-5 blocks) and completely stopped after block 4032.Wild-ass guess... someone had access to a pretty damn massive box or 2, was late to the party and decided to "get all them easy early coins"Or he might have noticed the weird nonces his setup generates and fixed it somehow.But my money is on "asshat with access to a large NUMA box (at work?)" [ ] I realize that "simple CWC" on wikipedia *is* CMWC4096. It's taking the time over 2015 blocks. Every 2016 blocks. Last time I checked, 2015 != 2016.In case you still don't get it, is the time taken from the last block with diff X to the first block with diff Y counted? Really?But honestly, thats just making a elephant of a simple implementation flaw, nothing to do with the theoretical properties of the proper algorithm.So back on topic... This idea actually looks promising, I yet have to run the numbers but I suspect it'll work "economically" as long as you keep the total adjustment possible over X blocks symmetrical for up vs. down (or even allow quicker up than down adjustment). Still somewhat worried about poisson noise causing issues for a faster-adjusting algo, but I guess that *should* average out over time... BlockHash_1_c=362436;BlockHash_1_i=4095;...BlockHash_1_rand();hmmm...http://school.anhb.uwa.edu.au/personalpages/kwessen/shared/Marsaglia03.htmlHope you didn't forget to credit Mr. Marsaglia for the CMWC4096 RNG Meni Rosenfeld:I never claimed otherwise, I only answered how I came to the conclusion that "naive algo with asymmetric limits is possibly disastrous".Zibbo:Sliding window is a interesting idea, you'd obviously have to reduce the per block adjustment factor and the limits to the 2016-th root to get the same overall adjustment speed as bitcoin, but at first look this should work without introducing new vulnerabilities and result in "smoother" adjustments (obv. not really *faster* if you use factors to end up with bitcoin-equiv adjustment rate, but less... well... blocky).kano:That's the whole point, the current network will happily accept chain-of-massive-number-of-low-diff-blocks over chain-of-less-harder-blocks as long as the sum of difficulty of the first is higher and it follows the "rules set in stone" (no invalid tx, generation amount <= calculated amount, difficulty == getNextDifficulty(prevblock), block nTime > median of prev 11 blocks, block nTime can't be more than 2 h in the future, ...).Assuming someone forks the chain, creating a chain with more work than the real network over the same real time obviously requires the attacker(s) having more hashrate than the rest of the network... you know, kinda the definition of a 51% attack.And as I already explained, creating such a low-difficulty chain starting at the same nTime as the real chain without having nTime of the forkchain blocks run off into the far future (as real clients wouldn't accept that, see above) *should* be impossible. But it isn't due to the off-by-1 in getNextDifficulty, am I talking Chinese here or something? I honestly have zero clue what he's talking about. But I have the slight feeling if it were true it'd be HUGE news in the cryptographic community... Yes, and I have an idea for a chain that will be completely fair, immune to all known attacks, any possible unknown attack and even impossible unknown attacks! Mining it will also produce more power than it consumes. So not only will it revolutionize the global financial economy, it'll also fix the energy crisis, cure cancer and shit rainbows! And it'll be done Real Soon Now(tm). A magic fairy told me bulanula is a sockpuppet of CH/RS.Well until you can disprove it, it can be assumed to be true and the guy who claims to be bulanula can actually be CH until you have concrete evidence to disprove this. I see, the SC shills are again out in force making libelous claims about their "competition".Guess they have to distract everyone from "2.0 Public Beta Testnet this weekend" followed by a whole lot of nothing... Yep, all the "fucking with timestamps" are "only" worsening the result of 51% attacks.The problem is this changes the economic incentives of miners, as "defecting" is suddenly a lot more profitable...Short version of the simple version, cooperators are mining "as planned", defectors fork the chain and communicate to collectively build a alternate version with optimally adjusted timestamps, N is the fraction of "cooperating" hashrate:Bitcoin as planned:N = 1 cooperate, everyone gets 1.N > 0.5 cooperate, cooperators get 1/N, defectors get 0.N < 0.5 cooperate, cooperators get 0, defectors get 1/(1-N).N = 0 cooperate, everyone gets 1.Solidcoin/ixcoin/i0coin/... with *1.1 /4 limits (edit: in theory, as the real chains all also have the same off-by-1 in their retargeting):N = 1 cooperate, everyone gets 1.N > 0.5 cooperate, cooperators get 1/N, defectors get 0.N < 0.5 cooperate, cooperators get 0, defectors get 3.6/(1-N).N = 0 cooperate, everyone gets 3.6.Bitcoin with off-by-1:N = 1 cooperate, everyone gets 1.N > 0.5 cooperate, cooperators get 1/N, defectors get 0.N < 0.5 cooperate, cooperators get 0, defectors get near infinite (really (what difficulty should be)/(minimum difficulty)).N = 0 cooperate, everyone gets near INF.edit: forgot, all current *1.1 /4 chains *also* have the off-by-1, so it's really "near infinite" for "defectors get a majority" there, too... Everyone got this? CoinHunter officially invited the attack, so no pre-warning this time, and no crying "EVIL BLACKHAT TERRRRRIST!!!" after. Nope, bitcoin still has the off-by-1, as for now it's deemed "too big to fail" and fixing it would mean a backwards-incompatible change to the blockchain.The off-by-1 fix is completely orthogonal to the NTP stuff.It's right here:https://github.com/Lolcust/GeistGeld/commit/f9523f33ec22e26b7781f5a545fc74b4ecdc31a6#diff-3Iirc my "why asymmetric diff adjustment is bad" was in a thread discussing SCs adjustment algo, and so far every asymmetric diff adjustment method I bothered to figure out a optimal strategy on has the same problem, a 51% attacker can create more blocks in the same nTime window than "he should be able to" while only doing the same # of hashes as the real chain over the same nTime window. And every time the factor gained happened to come out exactly as the maximum down adjustment over the maximum up adjustment for the same # of blocks.Trivial example for how time-based has the same flaw, let's say daily retarget and /4 *4 limitsofficial chain hashes along at difficulty 1 for 2 days, so it has 2 difficulty-days and takes 2 days worth of nTime.attackers chain has 0 blocks on day 1 (= diff retargets by /4), 8 times the normal blocks at diff 1/4 on day 2 (=diff retargets *4 and is back to 1 afterwards), so the attackers chain has a total of 1/4 * 8 = 2 difficulty-days, starts and ends with diff 1, also takes 2 days worth of nTime, but contains 4 times the # of blocks of the official chain. That 2M @ 0.0001 buy order ... not me.So, please dump enough coins... whoops, there's only 774K GG total in existence.Aka "more completely baseless FUD from mr. egomaniac to keep propping up vaporcoin".Or how did the "SC2.0 Public Beta Testnet this weekend" work out? Oh, right.Oh, and as a thanks for this nice personal attack, I'll gladly donate my expertise and if required a few days on my personal 5970s and/or LX150 cluster to break your chain to hell and back. cd srcmake -f makefile.unix bitcoindDuh. At the current point, yeah. tbx seems to have about 1200kH/s on it, fbx looks like about 150.So a potential attacker only needs something like 60 high end cpus or about 1000 really crappy ones to have a good chance at forking and overtaking the tbx chain, about 1/8 that for fbx. Yep, diff 1 is 2**32 hashes as in bitcoin to avoid even further confusing things.Minimum and initial tbx difficulty is/was difficulty 1/4096 (= 2**20 hashes).but your hash# calc is somehow off by a factor of 10, diff 0.0419... * 2**32 = ~ 180M, not 1.8G hashes/block avg. Well, here's what build output for me on sid amd64 looks like: http://pastie.org/2621383On ubuntu natty amd64 ... same thing. clone repo, qmake, make, , profit... errr... binary built!So... not sure wth is going wrong on your system.edit: just tried on natty i386 ... again same thing, builds fine. That's ... weird.I'm pretty much seeing *zero* of those building tenebrix on debian... Are you sure you started with a clean tree? head of what? Tenebrix, Tenebrix-daemon-exp or Tenebrix-miner?
Experimental pushpool branch for tenebrix: https://github.com/ArtForz/pushpoolrpc.target.bits set to 20 (1 share == ~1M hashes) seems to work pretty well locally. Well, if multicoin-qt builds on osx so should tbx, so "only" a matter of finding someone willing, able and trustworthy to build a binary... 0.015625 currently, looks like next diff will be 0.0625. Weeds. Doesn't sound too far-fetched, wouldn't be terribly surprised if the biggest single-GPU card ends up around 3.2-3.5Mh/J or so and a downclocked dual-GPU variant at least close to 4Mh/J. http://en.wikipedia.org/wiki/Koomey's_law Nope, difficulty works as in bitcoin, so at 20kH/s and difficulty 0.015625 you'd expect to find a block every 2^32 * 0.015625 / 20000 seconds on average (= ~56 minutes). Very roughly a factor of 1000.PhenomII hexcore here gets ~20Mh/s for BTC, ~20kh/s TBX. Wait, what? an algorithm *I* designed?Rule #1 of cryptography: do not design your own algorithms.What I did was modify multicoin to make replacing the block PoW hashing function easier, then plugged in scrypt (http://www.tarsnap.com/scrypt.html) with parameters of N=1024, p=1, r=1, feeding in the block header as password and salt, output size of 32 bytes.While those parameters would be way too low for a good password hashing/key derivation function (you want lots of margin for the future there), my initial educated guess and further experiments suggest they're still enough to "pessimize" current GPUs and FPGAs to a point where CPUs will easily be competitive... GPUs growing several MB of fast random access on-chip memory in the future might change that.And yes, choosing such "unusual" parameters is skirting the rule, but in this case imo acceptable risk. Worst case... someone manages to make a "efficient enough" GPU/FPGA/... implementation or a new gen of GPUs comes out, scheduled chain fork switching to higher N and p. Up to N=4096,p=8,r=1 or so time to verify the PoW hash on a CPU shouldn't be an issue, beyond that you'd have to add some measures to prevent "junk block spam" DoS. Yep, and price/perf is where FPGAs fall flat on their face.Why? Well, even at-cost a LX150 box still ends up at > $1/Mhps. And expected resale value is damn near 0.With GPUs not only is the initial cost lower, but when the next generation comes around you can resell them for somewhere around 50-70% of the initial cost, keep the rest of the system and replace them with their successors.If those end up about 40% better price/perf and perf/power (not totally unreasonable), you'd end up with the same hashrate as before but now using only 60% of the power. Repeat as often as necessary. Another benfit of that, with the short product cycles of GPUs, they'll be pretty much in warranty forever.So... why even bother with FPGAs then, other than being low power? Well... density (32 LX150s in a 2U = trivial, 48 = still no big problem) and reliability/low maintenance (server grade PSU, 80mm fans with > 60kh expected lifetime, ...)And of course having your own FPGA cluster to play with  Hey, that's news to me, so far my math and synthesis attempts say it'll suck on FPGAs, too. (wow, a algorithm designed to be expensive on specialized hardware ends up expensive on specialized hardware).so... [citation needed] or stop spreading FUD. Huh? Heavily undervolted GPUs coming even *close* to FPGAs? Seriously?So far the best I've seen from GPUs even with extreme undervolting is ~ 3Mh/J at the wall.My first 32*LX150 box with a power-hungry mobo, WAY overkill fans and running at 1250mV Vccint? 6.27Gh at 382W at the wall, thats a bit > 16Mh/J.A more optimized design, no overvolting, > 20Mh/J at the wall.And S6s are real power hogs compared to higher-end chips, smallish V6 and Stratix IVs get >30Mh/J easily (at atrocious price/perf, but hey...).For the math impaired, 20Mh/J at current difficulty -> 1BTC ~= 2kWh, that's $0.60/BTC at "european" $0.30/kWh and around $0.20/BTC at $0.10/kWh... yeah. No, thats *one 3GHz K10 CPU core* vs. a HD6970A 3GHz K10 core is roughly 3Mh/s doing double-sha256 aka bitcoinhash.A stock HD6970 is about 360-400Mh/s for bitcoinhash.Hey look, 3:360 == 1:120, a miracle!So yes, the factor of 1:5.2 is for ONE CPU CORE vs. a 6970.For the math or comprehension impaired, thats "A hex(=6)core PhenomII at 3GHz is a few % faster than a HD6970"And this is from actual measurements of real code running on real devices, not some "well, in theory it *should* be possible" numbers that overlook massive problems on real hardware.So... where is any written performance info for GPUs doing scrypt variants? The original paper only deals with VLSI, any citations?So I went for the "well, to get some numbers I'll actually have to try to write a optimized implementation" approach.So... maybe your GPU is 100 times faster than a CPU executing pure ALU code, but to do that you actually need to... like... store the per-thread state somewhere?So, where to put 128KiB (or 32 KiB using a factor 4 time/space tradeoff) of memory for V *per thread*?Registers? Way too small.LDS - works, but you only got 64KiB/CU so you end up with a max of 2 threads/CU even with a factor 4 time/space tradeoffGDS? way too small again.L2 read cache? You got 512k of that, so with a /4 reduction you can keep 16 threads worth of V arrays there, but that's not really helping a whole lot due to reasons I'll explain shortly.External GDDR5? Completely horrible for randomly reading 128 byte items all over the place.Now, ATI GPUs are funny beasts, they use something best described as "hyperthreading" similar to a niagara CPU to hide their 4-clock instruction latency. Which means you need to be executing 64 threads in parallel to make full use of a CU (16 VLIW4 cores * 4 deep pipeline).Best option so far is "use LDS, live with only being able to run 2 threads/CU (due to LDS size)... welll... thanks to what I explained above, that means you're effectively getting ALU throughput of half of one VLIW4 core per CU per clock.So a whole 6970 ends up effectively performing as if you only had 12 fully utilized VLIW4 cores.Well, turns using this approach in the real world, at 880MHz core clock and with overhead it actually manages roughly 5.2 times the performance of a single 3GHz K10 core.So, if you have any constructive suggestions on what other approaches to try to wrangle better performance out of a AMD GPU for this variant of scrypt, I'm listening.Inb4 obvious, first thing I tried was the KISS "just allocate a huge buffer for V arrays in global memory, run 64-256 threads and have the mem and L2 controllers figure it out." approach. also with time/space tradeoff factors of 2 to 16. Ends up slower than going with LDS. Yep, it's still very unoptimized.Just compiling scrypt.c in cpuminer with -O3 on amd64 linux ends up at 3.28kH/s/core on a AthlonII @ 3.6GHz. Option #2, giving up most of the memory-hardness to get a primitive useful for a iterated hashing PoW.Parameters used are N=1024,p=1,r=1 -> 128KiB of V.Not exactly much, but enough to give current gen GPUs a major headache.Basically, instead of aiming for "enough memory use to hit external memory on any device", aiming for "small enough to fit in L2 cache on CPUs, big enough to require too much on-chip memory/cache for running enough parallel instances to make GPU/FPGA/VLSI worth it."If a future generation of GPUs has several MB of fast on-chip cache (which would make em competitive), a forced update with increased memory usage and parallelism is on the wall (e.g. N=4096, p=4 or 8 ).And it'd still be "fast enough" to not cause too much of an issue with speed of verifying PoW, with N=4096,p=8 still only ~20ms per hash on a current decent CPU core.Notice that N=4096 p=8 r=1 is one of the parameter sets used in the scrypt paper for relative cost on specialized hardware.using the same cost/area figures for VLSI as the paper, rough relative estimates:md5=1double-sha256=6scrypt(1024,1,1)=1000000scrypt(4096,8,1)=40000000Or let's put it another way, best relative performance achieved real-world for sha256(sha256()), scrypt(1024,1,1), scrypt(4096,2,1) and scrypt(4096,8,1) for a 3GHz K10 core vs. a HD6970double-sha256 1:120scrypt(1024,1,1) 1:5.2scrypt(4096,2,1) 1:3.7scrypt(4096,8,1) 1:4.4That's without using vector instructions on the CPU, using a time-memory tradeoff for scrypt on the HD6970 that only stores 1/4 or 1/8 of V values and recreates the missing ones on the fly, straightforward GPU version was slower by a factor of 3-5. It's 2016 blocks with *4 /4 limits like bitcoin, just with 5 min nominal/block.Min difficulty is 1/4096 to account for scrypt(N=1024,p=1,r=1) being well over a factor 1000 slower than sha256(sha256()).There's no cmdline daemon yet, porting the multicoin-qt->tenebrix changes to multicoin should be pretty trivial. forgot --url http://127.0.0.1:8697/ ? on debian/ubuntu, install one of the libcurl4-dev packages Yup. Phenom II X6 @ 4GHz, amd64 linux[2011-09-26 15:17:36] thread 3: 5242 hashes, 2.59 khash/sec[2011-09-26 15:17:36] thread 1: 5242 hashes, 2.58 khash/sec[2011-09-26 15:17:37] thread 4: 5242 hashes, 2.58 khash/sec[2011-09-26 15:17:37] thread 0: 5242 hashes, 2.59 khash/sec[2011-09-26 15:17:38] thread 2: 5071 hashes, 2.58 khash/sec[2011-09-26 15:17:38] thread 5: 5242 hashes, 2.59 khash/sec the database format itself is compatible, the transaction logs are not. remove /database/log.* while bitcoind is stopped and you can happily switch from bdb5.1 back to 4.6 and similar stunts.
Pretty easy if you use COTS DC/DC converter modules.YV09T60 + input/output caps + 2kR 1% resistor = 12V->1.2V 60A, Vccint for 6 to 8 LX150.For Vccaux and Vccio a small 12V or 5V->2.5V DC/DC, 3A is plenty for 8 LX150+controller if you only have JTAG and 100MHz SPI.If you also need a few dozen mA @ 3.3V (for example for a USB transceiver), LDO from 5V or just grab it from the ATX psu.Trivial to design+build on a 2-layer PCB or even protoboard. use the full path to datadir I'll give you a big fat hint: maybe having a nice and regular structure for the W updates isn't the best option... Some of you guys have a reading comprehension problem?The LX25 is just for testing a new layout and reflow process. If it doesn't work it was cheaper than a LX150. If it does work you get a LX25 on a nice 0.1" breakout board.And yea, at low qty and without assembly $175 for LX150+discretes+board looks pretty much right.Also, LOL @ that toy heatsink. a 25*25*15 is barely enough, better to use a 30*30*20 or even a 40*40 if there's space for it. and you'll still need quite a bit of airflow. "You're doing it wrong"note that the byte order for displaying these hashes is basically exactly backwards vs. normal notationI'm using hex strings without quotes to show bytes-as-they-would-be-in-memory and in quotes to show uint256s in hex like in blockexplorer or returned by bitcoin rpctx hashes for that block:"3a459eab5f0cf8394a21e04d2ed3b2beeaa59795912e20b9c680e9db74dfb18c""be38f46f0eccba72416aed715851fd07b881ffb7928b7622847314588e06a6b7""d173f2a12b6ff63a77d9fe7bbb590bdb02b826d07739f90ebb016dc9297332be""59d1e83e5268bbb491234ff23cbbf2a7c0aa87df553484afee9e82385fc7052f""f1ce77a69d06efb79e3b08a0ff441fa3b1deaf71b358df55244d56dd797ac60c""84053cba91fe659fd3afa1bf2fd0e3746b99215b50cd74e44bda507d8edf52e0"again, that's when you read them as uint256s, little-endian all the way, so "bytes in memory" those really are:8cb1df74dbe980c6b9202e919597a5eabeb2d32e4de0214a39f80c5fab9e453ab7a6068e5814738422768b92b7ff81b807fd515871ed6a4172bacc0e6ff438be...so, to start the merkle building, we do sha256(sha256(h1 . h2)) for the first tworesult:2dd3ce205cf8d03f773d46d24becfd72c766deaa0d1327d7e4c810265f59a313again read it backwards because we display stuff in little-endian, and..."13a3595f2610c8e4d727130daade66c772fdec4bd2463d773fd0f85c20ced32d"looks familiar?do the same for "d173..." and "59d1..." and..."f6ae335dc2d2aecb6a255ebd03caaf6820e6c0534531051066810080e0d822c8"last pair..."a751efbeabe73bdf9d08df5760104feff915d9d807d4c62178cdeb98d8c25f43"now we only have 3, so last one gets concat'd with itself"13a3595f2610c8e4d727130daade66c772fdec4bd2463d773fd0f85c20ced32d""f6ae335dc2d2aecb6a255ebd03caaf6820e6c0534531051066810080e0d822c8"gives"59545fd8dfdd821ca7accecab0655d77437f5bba5aaa5ea8c042a26bc9ae514b""a751efbeabe73bdf9d08df5760104feff915d9d807d4c62178cdeb98d8c25f43""a751efbeabe73bdf9d08df5760104feff915d9d807d4c62178cdeb98d8c25f43"gives"15eca0aa3e2cc2b9b4fbe0629f1dda87f329500fcdcd6ef546d163211266b3b3"and final level of the tree"59545fd8dfdd821ca7accecab0655d77437f5bba5aaa5ea8c042a26bc9ae514b""15eca0aa3e2cc2b9b4fbe0629f1dda87f329500fcdcd6ef546d163211266b3b3"gives"9cdf7722eb64015731ba9794e32bdefd9cf69b42456d31f5e59aedb68c57ed52" Yep, and that's with 200ps clock jitter, your assumed 0-jitter clock would knock it down to 5.091ns cycle time => a bit over 196MHz On my real world rev1.1 boards with -2 speed grade, 1230-1250mV Vccint and 25°C ambient, this bitstream averages 193.9 MHz at very low error rate (0 errors over 2**35 hashes).Pushing up error rate to 0.1% => 198.3MHz average. And here the exact same HDL/settings but using ISE 13.2 and tightening timing a bit:Total REAL time to MAP completion:  30 mins 17 secs Total CPU time to MAP completion:   28 mins 23 secs Slice Logic Utilization:  Number of Slice Registers:                92,968 out of 184,304   50%    Number used as Flip Flops:              92,823    Number used as Latches:                      0    Number used as Latch-thrus:                  0    Number used as AND/OR logics:              145  Number of Slice LUTs:                     60,406 out of  92,152   65%    Number used as logic:                   34,257 out of  92,152   37%      Number using O6 output only:          21,087      Number using O5 output only:             409      Number using O5 and O6:               12,761      Number used as ROM:                        0    Number used as Memory:                   2,721 out of  21,680   12%      Number used as Dual Port RAM:              0      Number used as Single Port RAM:            0      Number used as Shift Register:         2,721        Number using O6 output only:           450        Number using O5 output only:             0        Number using O5 and O6:              2,271    Number used exclusively as route-thrus: 23,428      Number with same-slice register load: 23,414      Number with same-slice carry load:        14      Number with other load:                    0Slice Logic Distribution:  Number of occupied Slices:                15,446 out of  23,038   67%  Number of LUT Flip Flop pairs used:       60,460    Number with an unused Flip Flop:           868 out of  60,460    1%    Number with an unused LUT:                  54 out of  60,460    1%    Number of fully used LUT-FF pairs:      59,538 out of  60,460   98%    Number of slice register sites lost      to control set restrictions:               0 out of 184,304    0%Total REAL time to Router completion: 25 mins 23 secs Total CPU time to Router completion: 24 mins 26 secs ----------------------------------------------------------------------------------------------------------  Constraint                                |    Check    | Worst Case |  Best Case | Timing |   Timing                                               |             |    Slack   | Achievable | Errors |    Score   ----------------------------------------------------------------------------------------------------------  TS_coreclk = PERIOD TIMEGRP "tncoreclk" 1 | SETUP       |     0.233ns|     5.172ns|       0|           0  85 MHz HIGH 50% INPUT_JITTER 0.2 ns       | HOLD        |     0.316ns|            |       0|           0 As a little encouragement, here's a decent run for my old design (ISE synth+map+p&r, letting synth infer shift regs, no placement constraints, ...) for -3 speed gradeDevice Utilization Summary:Slice Logic Utilization:  Number of Slice Registers:                92,964 out of 184,304   50%    Number used as Flip Flops:              92,819    Number used as Latches:                      0    Number used as Latch-thrus:                  0    Number used as AND/OR logics:              145  Number of Slice LUTs:                     62,141 out of  92,152   67%    Number used as logic:                   34,288 out of  92,152   37%      Number using O6 output only:          21,087      Number using O5 output only:             424      Number using O5 and O6:               12,777      Number used as ROM:                        0    Number used as Memory:                   2,721 out of  21,680   12%      Number used as Dual Port RAM:              0      Number used as Single Port RAM:            0      Number used as Shift Register:         2,721        Number using O6 output only:           450        Number using O5 output only:             0        Number using O5 and O6:              2,271    Number used exclusively as route-thrus: 25,132      Number with same-slice register load: 25,117      Number with same-slice carry load:        15      Number with other load:                    0Slice Logic Distribution:  Number of occupied Slices:                16,519 out of  23,038   71%  Number of LUT Flip Flop pairs used:       62,163    Number with an unused Flip Flop:         2,573 out of  62,163    4%    Number with an unused LUT:                  22 out of  62,163    1%    Number of fully used LUT-FF pairs:      59,568 out of  62,163   95%    Number of slice register sites lost      to control set restrictions:               0 out of 184,304    0%...Total REAL time to PAR completion: 19 mins 45 secs Total CPU time to PAR completion: 20 mins 34 secs Timing: ================================================================================  Timing constraint: TS_coreclk = PERIOD TIMEGRP "tncoreclk" 182 MHz HIGH 50% INPUT_JITTER 0.2 ns;   3102658 paths analyzed, 386321 endpoints analyzed, 0 failing endpoints   0 timing errors detected. (0 setup errors, 0 hold errors, 0 component switching limit errors)   Minimum period is   5.262ns.  --------------------------------------------------------------------------------    Paths for end point XLXI_A/rb20/regt1_31 (SLICE_X104Y33.CIN), 252 paths  --------------------------------------------------------------------------------  Slack (setup path):     0.232ns (requirement - (data path - clock path skew + uncertainty))    Source:               XLXI_A/rb19/outE_17 (FF)    Destination:          XLXI_A/rb20/regt1_31 (FF)    Requirement:          5.494ns    Data Path Delay:      4.928ns (Levels of Logic =     Clock Path Skew:      -0.111ns (0.620 - 0.731)    Source Clock:         coreclk rising at 0.000ns    Destination Clock:    coreclk rising at 5.494ns    Clock Uncertainty:    0.223ns      Clock Uncertainty:          0.223ns  ((TSJ^2 + TIJ^2)^1/2 + DJ) / 2 + PE      Total System Jitter (TSJ):  0.070ns      Total Input Jitter (TIJ):   0.200ns      Discrete Jitter (DJ):       0.233ns      Phase Error (PE):           0.000ns      Maximum Data Path at Slow Process Corner: XLXI_A/rb19/outE_17 to XLXI_A/rb20/regt1_31      Location             Delay type         Delay(ns)  Physical Resource                                                         Logical Resource(s)      -------------------------------------------------  -------------------      SLICE_X126Y28.BQ     Tcko                  0.408   XLXI_A/rb19/outE<19>                                                         XLXI_A/rb19/outE_17      SLICE_X115Y27.A4     net (fanout=8)        1.658   XLXI_A/rb19/outE<17>      SLICE_X115Y27.A      Tilo                  0.259   XLXI_A/rb20/s1<6>                                                         XLXI_A/rb20/s1<6>1      SLICE_X104Y27.CX     net (fanout=1)        1.798   XLXI_A/rb20/s1<6>      SLICE_X104Y27.COUT   Tcxcy                 0.093   XLXI_A/rb20/regt1<7>                                                         XLXI_A/rb20/Madd_s1[31]_ch[31]_add_18_OUT_cy<7>      SLICE_X104Y28.CIN    net (fanout=1)        0.003   XLXI_A/rb20/Madd_s1[31]_ch[31]_add_18_OUT_cy<7>      SLICE_X104Y28.COUT   Tbyp                  0.076   XLXI_A/rb20/regt1<11>                                                         XLXI_A/rb20/Madd_s1[31]_ch[31]_add_18_OUT_cy<11>      SLICE_X104Y29.CIN    net (fanout=1)        0.003   XLXI_A/rb20/Madd_s1[31]_ch[31]_add_18_OUT_cy<11>      SLICE_X104Y29.COUT   Tbyp                  0.076   XLXI_A/rb20/regt1<15>                                                         XLXI_A/rb20/Madd_s1[31]_ch[31]_add_18_OUT_cy<15>      SLICE_X104Y30.CIN    net (fanout=1)        0.003   XLXI_A/rb20/Madd_s1[31]_ch[31]_add_18_OUT_cy<15>      SLICE_X104Y30.COUT   Tbyp                  0.076   XLXI_A/rb20/regt1<19>                                                         XLXI_A/rb20/Madd_s1[31]_ch[31]_add_18_OUT_cy<19>      SLICE_X104Y31.CIN    net (fanout=1)        0.003   XLXI_A/rb20/Madd_s1[31]_ch[31]_add_18_OUT_cy<19>      SLICE_X104Y31.COUT   Tbyp                  0.076   XLXI_A/rb20/regt1<23>                                                         XLXI_A/rb20/Madd_s1[31]_ch[31]_add_18_OUT_cy<23>      SLICE_X104Y32.CIN    net (fanout=1)        0.003   XLXI_A/rb20/Madd_s1[31]_ch[31]_add_18_OUT_cy<23>      SLICE_X104Y32.COUT   Tbyp                  0.076   XLXI_A/rb20/regt1<27>                                                         XLXI_A/rb20/Madd_s1[31]_ch[31]_add_18_OUT_cy<27>      SLICE_X104Y33.CIN    net (fanout=1)        0.003   XLXI_A/rb20/Madd_s1[31]_ch[31]_add_18_OUT_cy<27>      SLICE_X104Y33.CLK    Tcinck                0.314   XLXI_A/rb20/regt1<31>                                                         XLXI_A/rb20/Madd_s1[31]_ch[31]_add_18_OUT_xor<31>                                                         XLXI_A/rb20/regt1_31      -------------------------------------------------  ---------------------------      Total                                      4.928ns (1.454ns logic, 3.474ns route)                                                         (29.5% logic, 70.5% route)  hmm, the "peers disagree with NTP" looks more and more like it can pretty much only be a bad ntp response:Added time data, samples 17, offset -2 (+0 minutes)-2  -2  -2  -1  -1  -1  -1  -1  -1  -1  -1  -1  +0  +0  +0  +0  +0  |  nTimeOffset = -1  (+0 minutes)This is on a box with ntpd synced to a local stratum1 where the current SNTP code consistently gets < 10ms offset to local time from all pool.ntp.org servers I tried.The basic problem is... we can't trust the local clock to be accurate, and if median-of-peers and SNTP disagree by more than a few sec... which one is right?Gut feeling says if peers and NTP disagree by too much preferring median-of-peers time and issuing a warning might be better, current code uses NTP time and issues a warning under those conditions. Yup, 750Mh/s on a 240 is pretty easy. On a 195... tight. on a 130 or 75? Doubt it. Piling on top of the "These guys are getting completely insane discounts from xilinx or this is BS" crowd. Tested with Opera on linux here, all 4 cloudfront links give access denied.links on https://github.com/bitcoin/bitcoin/downloads - same result.Downloads from http://sourceforge.net/projects/bitcoin/files/Bitcoin/bitcoin-0.4.0/test/ work... the high reject rate is because cgminer is ignoring "target" in getwork and just blindly sends every H==0 share. so at diff 100 you'll see a 99% reject rate. Yup. Throwing 9 Gh of legit hashrate at it as a little "you must be at least *this* tall to 51% this" barrier.  Iirc the current implementation uses openssls default crypto RNG, so should be decently secure unless a debian maintainer comes by. *ducks* Yeah, if your system clock is off more than 10 sec or so, you pretty much need ntp=1 (hrrrm... actually it should be gracefully falling back to median-of-peer-time in that case... wtf?) block count would easily shed some light on this:60k+ = you're on the old GG chain without enablefullretargetperiod~350 = you're on the old GG chain with enablefullretargetperiod~240 = you're on the new GG chain without enablefullretargetperiod~1650 = you're on the new GG chain with enablefullretargetperiodlast one is the "real" chain. I *think* this might be some people running without enablefullretargetperiod=1, but I'm far from certain on that.     "blocks" : 1494,    "difficulty" : 111.50074768,= about 20min expected average at 400Mh/s 1. No.2. You still roughly need 51% to do it, so something like 15Th/s for bitcoin...
Weird, not seeing this here, so far had roughly 3% orphans. To get a "acceptable" stale rate at 15s/block you pretty much need a local poold w/ longpolling + cgminer. (at 15 s/block and with poclbm+friends 5s askrate and no LP, you're looking at something like 20% stales) It fixed the timewarp exploit. So now a 51% attacker can do what a 51% attacker is supposed to be able to do. But no longer "create 10000 blocks in 5 minutes" Err, what? we're at block 1373 and difficulty 66.46.Make sure you have the new build and enablefullretargetperiod=1 in your GG bitcoin.conf Yes. Obviously you'd put a chain checkpoint right before the switchover to prevent any future 51% attack from mucking with earlier blocks.GeistGeld reloaded is the first chain testing retargeting over the full period, we'll see how that goes. "51% Attacker can lower difficulty without driving up nTime due to flaw in retargeting algorithm" has been known since the start of Bitcoin? Got any proof of that? Coinhunter. Easily.While BEX has quite an attitude from time to time, he appears to have the competence to back it up (took me a while to figure out why his improvement of my attack would work so damn well against NMC).And IMO while CEXes move is a pretty dickish one, it's the only good way to simulate a attack on bitcoin (whole system, not only network).Any other forkcoin would be pretty much SOL as they lack the size, devs and infrastructure to make for a good guinea pig. (e.g. saying "well, we'll just add a chain lockin" is easy, but so far no one actually tested how hard it'll be to get all major players on a large *coin to update). another variant, which doesn't orphan anything:get a *massive* majority of miners to switch to nTime rules like this for mining:if ((pPrevBlock->nHeight+2) % retarget_block_count == 0)   set nTime as normalelse   block->nTime = medianofprev11()+1Once enough miners switch to this so that "legit miners finding 6 blocks in a row" gets unlikely enough so it doesn't occur over 2+ diff periods, difficulty starts decreasing.Adding some limits to make it head towards any arbitrary difficulty instead of going for "maximum decrease" is pretty simple. Depends, obviously this one is destructive, but there's a few variations on it.A "fun" one that doesn't require orphaning massive parts of the chain:With decently > 50%, only fork the chain if legit miners find > 5 blocks in a row (as that'd reset the median to where it should be) or the last block in a diff period (as that would prevent the wanted diff drop).Broadcast blocks as usual.Result: while things go mostly as normal (well, with quicker blocks the network now has over twice the hashpower and a few shortish chain forks getting orphaned), nTime of the chain except for the last block in each period basically stops increasing, and difficulty starts dropping after 2-3 retargeting periods.So basically "a majority of miner hashpower can decide to near-arbitrarily lower difficulty, and there's nothing short of a chain lockin or changing the retarget rules to stop em" Oh, and this also means this isn't a too massive issue for bitcoin simply due to the scale and time required (attacker needs more hashrate than the real net over at least 4-5 real retargeting periods for it to be somewhat effective, more time = more profit), but it could be pretty bad news for altchains. No, obviously you need to do the same or more total hashes as the real chain (it is a 51% attack...)The "bad" part is that you can make your chain have more blocks while having the same start and end nTime.And yes, it *should* be using 3-7, 7-11, ... but it doesn't. (probably to avoid the issue of the first interval after genesis, as you'd need to know when hashing of genesis started = the timestamp of the block before genesis).The code I'm currently playing with gets around this by special-casing that first retarget to have a nInterval-1 span instead of nInterval. Erm, no, those blocks are *valid*.By exploiting the fact that retargeting ignores one block interval every period, it's possible for an attackers' fork chain to "jump backwards in time" and create lots of blocks at low difficulty without running nTime off into the far future.Bitcoin (and most *coin) rules re. block timestamps:nTime has to be > median of prev 11 blocks.nTime has to be < now() + some buffer.let's say we have a chain with 4-block interval and 10 sec/block.Official chain, currect diff for hashrate, blocks found at nominal time:Code:blk#  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15time  0  10  20  30  40  50  60  70  80  90 100 110 120 130 140 150Now here's the weird part, we retarget after blocks 3, 7, 11, 15, and for block 3 we use 0 as first and 3 as last, for 7 we use 4 as first and 7 as last, ...so what happens if an attackers chain has blk timestamps like this:Code:blk#  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15time  0   1   2  30   4   5   6  70   8   9  10 110  12  13  14 150?first period (#3 - #0) is 30s as before2nd period is (#7 - #4) ... 66s3rd period is (#11 - #8) ... 104sWhoops.Obviously this ignores the "problem" of the attackers chain having way lower sum-of-difficultybut thats easy to fix:Code:blk# 16 17 18 19 20 21 22 23 ...time 16 17 18 19 20 21 22 23 ...just keep driving diff up at maximum speed until you have the same total work as the real chain.result-> the attackers chain does not violate the block timestamp rules, finishes at a *earlier* block timestamp than the real chain, ends up at a higher total work as the real chain, but contains way more blocks.This was done on the GeistGeld chain yesterday/today, so it's not a theoretical problem. 1. we need a clock accurate to at least "block in future window"/2, better doesn't hurt. Bitcoin just uses the median of peer times as thanks to the large diff period and block-in-future window it can tolerate up to an hour or so of offset.2. It's not a full NTP impl, just stupid SNTP w/ RTT correction (usually +-1ms on a box with properly working ntp)(and i0s original code doesn't even do RTT correction...).3. Got a cross-platform way to determine if the system we're running on has a running and working ntpd? Does windows even have real NTP support? iirc even W7 only has a SNTP daemon to periodically sync ala ntpdate-from-cronjob. 10sec in the future should be plenty narrow enough. The simple version of my attack for a 240s retarget period needs at least a 960 sec "in the future" window for maximum effectiveness.Have to check the ntp code you used, if it's my 'fixed' version of kr105s original code it's not very nice to pool.ntp.org (queries the same NTP server every 5 min).I swear I have a way better one around here somewhere (runs NTP in seperate thread, takes round trip time into account, only queries ntp once per hour after initial sync, compares local, ntp and median of peer times and warns user if theres a large difference). from my sims, asymmetric diff adjustment of any kind is "bad". makes it possible for a cartel to put more blocks per timespan and still end up with the correct sum-of-difficulty (for SC-and-clones *1.1 /4 that nets you the ~x3.5 "attack") Only way I see to fix the "someone produces blocks in the future to fuck with diff" problem is... to narrow the accept window a lot. When moving zombie-i0 to 90 sec/block and retarget every 3h I lowered the window to only allow blocks up to 5 minutes in the future (could've done 15 seconds as well, one benefit of the [somewhat half-assed] NTP support).edit: 10 seconds or so *should* work for geist. guess miners will simply have to make sure they have a accurate clock on their boxes *g*edit2: I have some finished-but-needs-more-testing NTP code around here somewhere that I indended for zombie-i0 v1.2, if anyone is interested... A bit over 3400, around 4 blocks/sec average (= around 13% effective hashrate). bitcoind still starts lagging like hell beyond 3 blocks/sec or so  Nope, but before I was always mining @ effective diff 1 due to H==0 checks in my miners and poold.Also gave me an opportunity to test some of my bitcoind/pool performance improvements on a "live" network. Ok, done.In case anyone is wondering what on earth that storm of blocks was, a slightly optimized bitcoind with 9Gh of miners @ diff 0.0625. Trying something, hold on to your hats.
should be possible to make bitcoins algo work for such short intervals.Main thing, don't accept blocks that far into the future, current clients are accepting blocks up to 2h in the future. *bad* idea if your retarget interval is 4 minutes. Wow, I stop it for a bit and diff shoots back up to > 120 like instantly... Yes, it's supposed to.But by adjusting the timstamp of the first and last block in each diff period you can make it retarget /4 *every single time*  Yes, my miners are producing blocks with "creatively adjusted" timestamps.Using the rules I posted. 3Gh, and I'm not orphaning other miners blocks on purpose. Code:        // Update nTime        if ((pindexPrev->nHeight+2) % 16 == 0)            pblock->nTime = max(pindexPrev->GetMedianTimePast()+1, GetAdjustedTime() + 1800);        else if ((pindexPrev->nHeight+1) % 16 == 0)            pblock->nTime = pindexPrev->GetMedianTimePast()+1;        else            pblock->nTime = max(pindexPrev->GetMedianTimePast()+1, GetAdjustedTime());*walks away whistling* Nah, 1st one is probably someone discovering the "joy" of a hard 4kB tx size limit (*way* more convenient than those EVIL variable tx fees, eh?)2nd seems to be for some reason stuck downloading the chain and keeps DCing his peers thanks to the "disconnect peer if he sends us more than 9 orphan tx" "improvement". *shrug* I still don't see how LGPL is more restrictive than SleepyCat, but... guess we'll have to disagree on that. Just tested, cgminer happily mining at 1% CPU on a win7 box on dual 6970s, cat 11.6 (driver only) + sdk 2.4 I just don't see the massive problem here. SleepyCat (in my book a way "stronger" copyleft license than LGPL) is ok because you can rewrite the database interface, but simply removing the GUI or forking the old wx GUI is ... what? impossible? Well, just compare previous releases claims with actual changes.doublec was nice enough to break em out into nice logical units: https://github.com/doublec/solidcoin/commits/masterThere's quite a few WTF candidates in there. While 2 pipelines could theoretically fit on a S6-LX150, routing is impossible (S6s have a lot less "long" routing resources than virtexes).What *is* possible is one pipeline with 2 register stages per sha256 round, use SRL16s for W where possible, don't go overboard with em and don't let synthesis infer more shift regs.And don't expect to get > 170MHz or so post-p&r on -2 without giving the placer some help.*edit, SRL16, nor LSR16*edit2: the xilinx docs aren't very clear on this, but a LUT6 in a SLICEM can be used as *2* equal-length SRL16s => a 32-bit wide shift reg up to 17 deep (slice FFs give the last stage) is only 4 SLICEMs. The slow processing? Can't be fixed for now (not unless you pull in some rather... experimental... bitcoin changes).The txindex journal bloat? https://github.com/bitcoin/bitcoin/pull/491 We're statically linking BDB4.7 already. Read that license?edit: to save some hunting, here it is:Code:/* * Copyright (c) 1990,2008 Oracle.  All rights reserved. * * Redistribution and use in source and binary forms, with or without * modification, are permitted provided that the following conditions * are met: * 1. Redistributions of source code must retain the above copyright *    notice, this list of conditions and the following disclaimer. * 2. Redistributions in binary form must reproduce the above copyright *    notice, this list of conditions and the following disclaimer in the *    documentation and/or other materials provided with the distribution. * 3. Redistributions in any form must be accompanied by information on *    how to obtain complete source code for the DB software and any *    accompanying software that uses the DB software.  The source code *    must either be included in the distribution or be available for no *    more than the cost of distribution plus a nominal fee, and must be *    freely redistributable under reasonable conditions.  For an *    executable file, complete source code means the source code for all *    modules it contains.  It does not include source code for modules or *    files that typically accompany the major components of the operating *    system on which the executable file runs. * * THIS SOFTWARE IS PROVIDED BY ORACLE ``AS IS'' AND ANY EXPRESS OR * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED * WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, OR * NON-INFRINGEMENT, ARE DISCLAIMED.  IN NO EVENT SHALL ORACLE BE LIABLE * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. */ I guess we're agreeing then. IMO the current bitcoin economy is not anywhere near the size and the future way too uncertain to have anyone blow the money required on the NRE of designing a real ASIC at a competitive structure size. But who knows. Nope. Probability of a attacker with a given % of network hashrate (below 50%) to successfully find N blocks in a row before the rest of the network does is independent of average time/block. See the original paper.Now, here's the fun part: What about the probability of our attacker succeeding at least once in fixed timespan?  If you could read, I wrote sASIC, aka structured asic, pretty much the same thing as xilinx easypath but without the niceness of 1:1 FPGA-to-ASIC on a HDL level. You forgot a few:I never provided any proof I had a opencl miner capable of ~150Mh/s on a 5770 back in july 2010.I never provided any proof I had a CAL IL miner doing ~650Mh/s on a stock 5970 about 3 months later.I never provided any proof of starting development of a sASIC miner around the same time.I never provided any proof of getting actual devices in early march, which while providing excellent hash/J sucked at attainable clock(= hashrate) relative to cost.And you'll probably also never see any proof I've managed to get a good deal > 200Mh/s from a S6-LX150. A *bad* version of the attack could have looked like this:Create one 1-input 10000-output transaction splitting 100.01 SC into 10000 * 0.01 SC + 0.01 fee (one output is ~35B, so only about 350kB or so). Submit it to other nodes and wait for it to get included into the chain.While offline, create 10000 1-input 10000-output transactions, each spending one of those 0.01 and splitting it into 10000*0.00 + 0.01 fee (yes, that would have been a valid transaction!), collect all of them with a half-a-node or similar.Inject those 10000 transactions (~350kB each) into the network at multiple points from machines with decent pipes (again, not too hard to do using half-a-node as a base).Sit back and watch the show as nodes on the network try to cache and propagate 3.5GB of transactions. I dont know of any recent fix making the blockchain growing uncontrollably.The only issue I am currently aware of is that under certain circumstances the disabling of orphan block storage can possibly cause nodes to never catch up to the current head of the chain and under similar circumstances can also cause them to spam 1000s of "GetBlocks" requests while downloading the chain.
Not disagreeing with you here. Though I do regret not noticing the massive txdb journal growth earlier, or I would have stopped the "attack" a lot sooner than I did. "Your rules allow anyone to send transactions up to nearly BLOCK_SIZE_GEN for 0.01 coins" pretty much sums it up.There was no microtransactions DDoS or anything the like.One node. Sending 71 transactions with 350~430kB each over the span of 17 hours..Take a look yourself: http://john-edwin-tobey.org/scbig.txtThey're in Blocks 28351 to 28481 in case you didn't notice. For which part?Telling RS/CH/His Royal Highness that his changed fee rules were allowing massive tx for nearly free?Using the system within said rules after getting told that those rules are perfectly fine?Finding a lack of optimization inherited from bitcoin in the process?Informing the bitcoin developers about said lack of optimization and submitting a patch that (well, at least partially...) fixes it?</troll> "I had already fixed the issues which artforz was taking advantage of to disrupt service to thousands of people."Right. He had already fixed it. So *thats* why it took him THREE releases to get his half-assed "fix" right and the current release still happily creates 6.8GB of temporary txdb journal bloat while downloading the chain.*facepalm* *ponders writing a response**checks viperjbms post history**wanders off* Oh, and if you think the orphan block handling "improvements" (aka completely disabling it) in 1.031 doesn't hurt anything (well, other than nodes not catching up to the current block under certain circumstances)...grep your debug.log for "getblocks".Notice some nodes appear to be sending a GetBlocks for *every single block they get* while downloading the chain?Notice the block #s are nowhere near the "bad evil hacker" blocks?You got 3 guesses which versions are exhibiting that broken behaviour. I'd re-enable handling orphan blocks (add a size limit on the orphan blocks list if you are afraid of orphan floods), or the SC network will soon be quite dead (it's already starting to fork ...). Guess you can't kill the undead.  Can't wait to see what dear leader will break this time and how the apologists are going to explain it away again.  1. it's *A*ffects, not *E*ffects, unless it *caused* those chains.2. No, it doesn't affect all chains, at least not as seriously. As such a large transaction (rightfully) incurs large fees on the any network using bitcoins original fee rules.3. Nothing got taken down. A few SC nodes apparently crashed because they ran out of disk space due to the database journal growing to a *massive* 6GB. Something in bitcoins block processing seems to produce DB writes scaling O(N**2) with # of tx inputs/outputs. Note that the network was still happily processing transactions and finding blocks the whole time and most users saw nothing except slightly increased CPU and bandwidth use.4. 80 transactions. Valid according to the network rules. Spread out over 12 hours. Maybe you should report coinhunter for hurting your private investment by first changing bitcoin rules without considering the consequences, then telling people that try to tell him why it's a bad idea to fob off, then "fixing" it by changing the rules half-assedly and potentially breaking every exchange and pool.edit: Did I mention the "anyone still running 1.02 or earlier now runs the risk of creating transactions that will sit at 0/unconfirmed forever" part? I'm pretty sure someone else didn't when releasing 1.03... No p2p broadcast network is 100% secure against flooding, it's always a matter of degree.Doing the EXACT SAME THING (80 400kB transactions) on the bitcoin network would have cost about 80BTC in fees.80BTC vs. 0.80SC @ 0.01BTC or so, nearly the same thing except for that tiny 4 orders of magnitude difference. Yes. It appears any time-triggered system or asymmetrically adjusting algorithm using block timestamps can be gamed by a 51% attacker.What's worse, the same thing can be done by a 51% collective of attackers without requiring any central coordination other than agreeing on a starting block and what rules define a "properly fake" block timestamp. Well, it does have this vulnerability, but at *way* higher cost.old SC rules:Spamming the network with transactions, 0.0005BTC/kB vs. 0.000025SC/kB.Filling blocks to 250kB, same fees. Beyond 250kB it gets exponentially more expensive for BTC, stays the same for SC.current SC rules:0.0025SC/kB.imo way better, but still a tad low (and legit users are hitting the 4kB tx limit).also maybe one point to consider, back when BTC was worth about as much as SC is today, the fee was 0.01BTC/kB.Btw, some nodes crashing was probably due to running out of disk space (as it seems to have mostly affected small VPSes), as somehow 28MB of transactions in blocks produced 5GB of database commit journals. That *is* caused by a bug/lack-of-optimization in bitcoins block processing and the devs have been notified.Also maybe worth noting: making all nodes forward, process and store those 28MB of transactions cost 0.78SC, even with the fixed rules it's 78SC... that's still only about $6. So better not piss off any bored kids with pocket change until reasonable tx limiting rules are in place. Cherry G81-3000.No-frills 105-key wired keyboard that's stiff enough for me and doesn't wake the dead.Cherry MY microswitches = linear actuation, 60g actuation force, > 100g to bottom out.Sure as hell doesn't beat a model M, but so far it's the best non-clicky keyboard I found. If you still get that error after deleting everything but wallet.dat (that includes the /database/log.* files)... yeah, you're probably screwed.Last resort, iirc in the dev section someone posted code to pull anything that looks like a privkey out of a corrupt wallet.dat, then you can 'simply' inject them into a fresh wallet on a bitcoin with the privkey import/export patch and finally do a -rescan. Not directly related, but here's an example of "unintended consequences".The problem with any *coin using a asymmetric difficulty adjustment is, it gets some economic incentives re. mining backwards.I'll use SCs algo (or the work-alikes like Zombie-i0 and soon ix) as a example.It's highly profitable for miners to start a "cooperative cartel".Simplest scenario (again, this is for a SC-like algo with *(10/9) /4 limits):all miners in the "cartel" add the following new rule for creating and accepting blocks:if (prevBlock.nHeight % (blocksPerDiffPeriod * 6) < (blocksPerDiffPeriod * 5))    block must have curblock.nTime == prevBlock.nTime+1else    normal block nTime rules apply.Once the cartel has a hashrate majority, difficulty settles to oscillating around a bit under 1/3 of what it should be given the cartels hashrate and remaining legit miners get zilch (well, they can still get a few blocks in the 1/6 of time where the cartel follows normal rules).And even if 100% of hashpower switches to the cartel rules, the network will still oscillate around a difficulty 1/3 of where it should be.So once the cartel miners have enough hashrate to orphan the main chain, it's highly beneficial for all remaining mainchain miners to also follow the cartel rules -> good luck stopping it again. What DDoS? *one* node sending *one* completely valid transaction when its previous transaction got into a block.I told you about this problem in private and your response was calling me an idiot because it's a total non-issue.I demonstrated why it's an issue. yup, radeonvolt Webcited for posterity. http://www.webcitation.org/61N4Pv8C7 110C is pretty high for stock cooler and non-overvolted.here's VRM temps from one of my quad 5970 boxes @ stock V, 21°C ambient, 830-870 core, 300 mem, fans 60%75 / 75 / 73 C90 / 93 / 90 C71 / 72 / 69 C81 / 83 / 82 C70 / 73 / 69 C87 / 87 / 87 C66 / 67 / 64 C84 / 91 / 86 CCore temps are in the 62-66 C range.System fans are 2 3kRPM 120x38 delta AFB for the GPUs, 1 for PSU + CPU section.Btw, 70 C sounds about right for VRMs on a watercooled overvolted setup, a bit high but some 5970 blocks don't have the greatest VRM cooling.
Guess digbtc is just massively unlucky. Estimated network hashrate is ~95Gh/s and the last 60 blocks were ~120s/block average -> another 30% or so diff decrease at block 19200 (= in about 2h or so at current hashrate). Unless I missed something, then that's correct, but only if you interpret it in a certain way.With the same relative hashpower vs. the rest of the network, over the same # of blocks, chances of finding X blocks in a row are the same, doesn't matter if avg. time/block is 10 seconds or 10 days.But... wouldn't a theoretical attacker care more about how much time it takes to get a successful double-spend instead of how many blocks? No, they're not. Do the math. They don't even have to turn off mining1. Pull a mining cartel attack and fork the chain when another miner finds a block.2. Start fucking with block timestamps.3. . 4. Near-infinite number of blocks! Where did I say that?Which pretty much describes the "development" style of Satoshi and other early devs.I'd have to check the commit logs, but I noticed that long ago and just shrugged, as compared to other *cough* "tiny issues" that's a pretty trivial one.No, I'm pretty sure the core devs never noticed there was one. Or was that a rhetoric question?./bitcoind backupwallet filename_to_save_backup_as.If your system corrupts a transactional BDB database on power loss, it is broken. And no amount of trickery gets you 100% around OSes/ddisks lying about flushing buffers.Actually, yes. Backing up a live journalled DB properly is not trivial (the current backupwallet cheats by waiting for all accesses to stop, then flushing the logs and backing up the main datastore).Wow, really? *rollseyes*Yep, as you addressed only current user-visible issues but ZERO of the major issues in the core.Agreed.Agreed on the part about satoshi, but there's been pretty constant improvementYep.What false worship? Stop making shit up. I'm saying the current devs are doing pretty well at trying to sort out the mess and get a maintainable codebase instead of adding cosmetic changes and calling them "great improvements".BTW, have you figured out the tiny problem that SCs (and i0s, and soon IXs) difficulty adjustment algo creates when faced with a attacker with majority hashpower yet? Yeah, unit tests, test suites, ... who needs that shit for a network handling $M of transactions daily? Just focus on adding features to the GUI! *facepalm* Just a small hint, the new diff algo makes a 51% attack *really* profitable, I'll leave it to you to figure out why. Pretty sure I fried one of those with 4*HD5770 (stock V, OCed to ~1000/300).Replaced it with a AeroCool E85-700 (HEC-700TE relabel). I really liked the first part of this one: https://github.com/ixcoin/ixcoin/commit/a489c4b0a4bf57a4c8807995cf806fd666760135 Yes. Solo it only reports 1 accepted/rejected when it finds a block (or finds a stale block solution...). Gui client works fine for solo mining if you start it with -server or put server=1 in your i0coin.conf (don't forget to also set rpcuser and rpcpassword)just tested the new i0coind on win7, also works Hmm, tested the gui client in win7 here, works fine except for some weird graphics glitch in the background of the toolbar area. Hmmm... wild guess... it might not be showing unconfirmed rewards? (stopped mining @ bitparking ~block 15300) Hmmm, on "bitparking pool seems unlucky"...Blocks Found   24Balance   1269.575216314 Okay, here's the gist of the new retargeting rules.target time per block is 90 seconds.difficulty is adjusted every 120 blocks (= 3h nominal).upward difficulty adjustment is roughly: +11% if avg time/block over the last 120 blocks was < 30s +6% if avg time/block over the last 120 blocks was < 60s +3% if avg time/block over the last 120 blocks was < 90sdownward adjustment if time/block is > 90s is proportional and limited to /4.= the same limiting algo as solidcoin, just over 120 instead of 240 blocks. You old wallet does not confirm? what does that mean?If it's a send stuck at 0/unconfirmed it should confirm eventually.If it's a receive stuck at 0/unconfirmed... it'll probably be stuck at 0/unconfirmed until the user that sent it upgrades (detailed reason: a client will only resend a transaction after it has seen a new block not containing the tx. old clients don't see any new blocks -> they won't resend tx.) Hmm, tried restarting the client? You might've gotten a bit unlucky and only connected to nodes running the old version (which doesn't pass along the new-rules blocks). Installed? it's just a zip containing the client and daemon exes. https://raw.github.com/fusebox/i0coin/master/I0coinClientv1.zip <- win32 binaries Yep. existing wallets should work fine, same for existing blk001/blkindex and... really... everything.
Still 256, probably not for long. i0pool.bitparking.com is already at > 20Ghps ... Seems to be working, we're at block 14641 and diff is 256 as expected.... 14642... 14645... I think I'll direct my miners elsewhere now (inb4 "STOP HOGGING THE BLOCKS") Sure, we can switch after block 16127, at diff 16384 and a exchange rate of 0.0006 those remaining 1495 blocks should be done in ... 6 months or so. First stab at adding a 3s recv timeout to the NTP stuff, I *hate* asio.Code:diff --git a/src/util.cpp b/src/util.cppindex 31dcb57..cfd1932 100644--- a/src/util.cpp+++ b/src/util.cpp@@ -839,6 +839,17 @@ time_t GetNTPTime( const char* ntpServer )  socket.send_to(    boost::asio::buffer(data),    receiver_endpoint);+ //ugly hack, CBA to switch to asio async I/O just to get a 3 sec timeout+ int hSocket = socket.native();+ fd_set fdset;+ FD_ZERO(&fdset);+ FD_SET(hSocket, &fdset);+ struct timeval t;+ t.tv_sec = 3;+ t.tv_usec = 0;+ int n_readable = select(hSocket+1, &fdset, NULL, NULL, &t);+ if (!n_readable)+  return time_t(0);  socket.receive_from(    boost::asio::buffer(data),    sender_endpoint);@@ -890,10 +901,17 @@ int64 GetAdjustedTime()    if((time - nTimeNTPLastSync) >= (60 * 5)) // Calculate the NTP offset once every 5 min  {-  int64 ntpTime = GetNTPTime(); -  nTimeNTPOffset = ntpTime - time;   nTimeNTPLastSync = time;-  printf("nTimeNTPOffset=%d\n",nTimeNTPOffset);+  int64 ntpTime = GetNTPTime(); +  if (ntpTime)+  {+   nTimeNTPOffset = ntpTime - time;+   printf("nTimeNTPOffset=%d\n",nTimeNTPOffset);+  }+  else+  {+   printf("NTP timeout\n");+  }  }       return time + nTimeNTPOffset;it compiles, seems to work and doesn't lock up or crash the client... so far. right, the NTP hangs... let's see how hard adding a short timeout would be... for the switch-to-256 thing...Code:--- a/src/main.cpp+++ b/src/main.cpp@@ -726,6 +726,9 @@ unsigned int static GetNextWorkRequired(const CBlockIndex* pindexLast) //okay, maybe not this line     if ((pindexLast->nHeight+1) < 14640)        return GetNextWorkRequired_OLD(pindexLast);+    //hardcoded switch to 256.0 difficulty at block 14639+    if ((pindexLast->nHeight+1) == 14640)+        return 0x1C00FFFF;      // Only change once per interval     if ((pindexLast->nHeight+1) % nInterval != 0)should work ? +1Eternal september just got a lot more bearable. Actually, just realized something... as ix will also switch to 3-min blocks but has 96 coins/block... that's twice our inflation rate... can't have that.so... either also switch to 96 coins/block (boooring!) or go to 90 seconds/block target while keeping the 48 coin reward.At 90 sec/block... change retarget to every 120 blocks (= every 3h nominal), keep the *1.1 /4 limit per retarget, change block acceptance rules so blocks can't be more than 5min or so in the future (we still use bitcoins 120min, but we have way more accurate time thanks to integrated NTP...)And while we're at it, go to diff 256 instead of 4096 after block 14639."special" enough? It's also still plenty profitable for people that saw the trend early and went for significantly more efficient hardware instead of "LOL MOAR 5830!!!". At USD 0.01 it's still a ripoff   Sapphire extreme 5830/5850? Lüfter extrem wertig? Lol, das war'n guter!Das is der selbe schrottlüfter mit china-extra-weich gleitlager den sie auch schon auf ihren älteren billig-58xx verbaut hatten.3 monate @ 100% und das ding hat sich entweder gefressen oder is so ausgeleiert dass der rotor eiertanz spielt. And people wonder why most old timers just switch on their mental killfile on here... Well, once theres reasonable consensus on what the new algo should be, it's just a matter of changing the constants and finding a suck... masochi... kind soul to build binaries.Probably not a too good idea to open a exchange back up before "everyone" switched and the network gets at least a few dozen Ghps. Well, thats what my patch does, switch to straight solidcoin algo after block 14639 (180s/block, diff increase limit, retargeting period 240 blocks), but keep i0s 48 coin/block reward.-> diff should adjust by /4 after 14639, and at 4096 diff even single-digit Ghps should be able to sustain at least 1-2 blocks/hour or so.I guess we could just disable the 7-day thing and keep i0s retargeting algo, but then we'd be stuck at diff 16384 for a looooong time. "It compiles, ship it!"On a more serious note, for a merged mining currency it'd be better to start a fresh chain and not be associated with the general failure that is ix/i0 (and namecoin testnet already has a working implementation). I think you messed up the genesis "pszTimestamp" string literal while editing.for portability it should prolly be changed toCode:const char* pszTimestamp = "15/Ago/2011 - Diario El Dia - Obama cae al 39% en la aprobaci\xf3n ciudadana";notice the \xf3 escape in the string, it's a literal 0xf3 char in the original source. iirc thats not valid C++ and tends to get broken easily by a editor using the wrong codepage. Me-too.CX series is group regulated, needs some load on +5. As plenty other people said HD/DVD makes for a good "dummy load".Btw, why on earth don't people get a $5.99 multimeter and just measure the output voltage? nice hack, but innovative?https://bitcointalk.org/index.php?topic=24605.0 Did you have >= 26.00 balance in your wallet at that time?If yes... that's very odd (and worthy of further investigation).If no... known bug (client throws away sub-cent change as fee if it can't add another input to make the change >= 0.01), will be fixed in 0.3.25. Well, kr105 seems unable/unwilling/busy/run over by a bus... so... *shrug*.
If the ref cards fan doesn't die within the first month or so (= manufacturing defect), it'll probably last near forever.The sapphire extreme 5830/5850... not so much, those have really cheap sleeve bearing fans. I'd be surprised if it lasted much over 6 months at 70%. Right under Products -> Cooling -> VGA -> Accelero XTREME 5970 -> Support"Advice for installation on ATI HD 5970"http://www.arctic.ac/en/support/support/detail/question/95-advice-for-installation-on-ati-hd-5970.htm"Manual : Accelero XTREME 5970"http://www.arctic.ac/index.php?eID=tx_mm_bccmsbase_zip&id=14140256894e56258d0a992And yeah, the backplate isn't held on by anything once you remove the screws. If they aren't overvolted... I'd say "yes, but".The AX850 is a pretty good PSU, just look at JGs review OCed 5870 at stock V is 200-220W, like 180 with mem @ 300OCed 5970 at stock V is ~300W, about 270 with mem @ 300Stock wattage is ~ the same as OCed with underclocked mem.So that's < 700W load on a PSU rated for 840W continous on 12V.now, theres the "but" part... simple, I wouldn't want to run a PSU at > 80% rated 24/7 for months. Wait, you tried installing a accelero 5970 with NO INSTRUCTIONS?Sounds like you killed your card improperly installing it then.The installation instructions that come with it (and are also available on ACs website) state VERY clearly to leave the backplate on and to *NOT* fully tighten the 4 x-plate screws around each GPU or the screws mounting the main cooler to the board (it's ok to fully tighten the 2 screws holding the VRM heatsink).Overtighten the x-plates and you kill your DVI outputs.Overtighten the standoffs (especially with no backplate) and you bend the board so badly it's usually a paperweight. 5970s at stock V are < 300W.at 850/300 and stock V they're also < 300W.930/1000 at 1150mV ~400W eachSo that PSU should be fine as long as you don't overvolt em. Yep, does it power on with just green/black shorted?Also, it's generally a VERY bad idea to only load old/cheap 300/350W PSUs on +12.Those are pretty much all group-regulated designs taking feedback from +5V or +3.3V -> load +12 significantly with +5/+3.3 unloaded and +12 ends up *way* low, I've personally seen < 9.5V with 60% rated load on +12 and nothing on +5/+3.3. Something like this should do the trick (disable the broken one-week crap, switch to solidcoin algo after block 14639).Code:diff -Nur I0coinClientv1.0-linux-stable-orig/src/main.cpp I0coinClientv1.0-linux-stable-dev/src/main.cpp--- I0coinClientv1.0-linux-stable-orig/src/main.cpp 2011-08-18 23:15:50.000000000 +0200+++ I0coinClientv1.0-linux-stable-dev/src/main.cpp 2011-08-25 08:23:52.143725519 +0200@@ -644,7 +644,7 @@     return nSubsidy + nFees; } -unsigned int static GetNextWorkRequired(const CBlockIndex* pindexLast)+unsigned int static GetNextWorkRequired_OLD(const CBlockIndex* pindexLast) {     const int64 nTargetTimespan = 7 * 24 * 60 * 60; // two weeks     const int64 nTargetSpacing = 5 * 60;@@ -659,6 +659,7 @@     // Only change once per interval  if ( nRemaining != 0)  {+/* HORRIBLY BROKEN, *NEVER* use time() in here   const CBlockIndex* pindexFirst = pindexLast;    for (int i = 0; pindexFirst && i < nRemaining-1; i++)    pindexFirst = pindexFirst->pprev;@@ -666,6 +667,7 @@      int64 rema = GetAdjustedTime() - pindexFirst->GetBlockTime();   if(rema < nTargetTimespan)+*/    return pindexLast->nBits;  } @@ -691,6 +693,71 @@      if (bnNew > bnProofOfWorkLimit)         bnNew = bnProofOfWorkLimit;++    /// debug print+    printf("GetNextWorkRequired RETARGET\n");+    printf("nTargetTimespan = %"PRI64d"    nActualTimespan = %"PRI64d"\n", nTargetTimespan, nActualTimespan);+    printf("Before: %08x  %s\n", pindexLast->nBits, CBigNum().SetCompact(pindexLast->nBits).getuint256().ToString().c_str());+    printf("After:  %08x  %s\n", bnNew.GetCompact(), bnNew.getuint256().ToString().c_str());++    return bnNew.GetCompact();+}++//blatantly stolen from SolidCoin+unsigned int static GetNextWorkRequired(const CBlockIndex* pindexLast)+{+    const int64 nTargetTimespan = 12 * 60 * 60; // 12 hours+    const int64 nTargetSpacing = 3 * 60;    //3 minute blocks+    const int64 nInterval = nTargetTimespan / nTargetSpacing;++    // Genesis block+    if (pindexLast == NULL)+        return bnProofOfWorkLimit.GetCompact();++//okay, maybe not this line+    if ((pindexLast->nHeight+1) < 14640)+        return GetNextWorkRequired_OLD(pindexLast);++    // Only change once per interval+    if ((pindexLast->nHeight+1) % nInterval != 0)+        return pindexLast->nBits;++    // Go back by what we want to be 14 days worth of blocks+    const CBlockIndex* pindexFirst = pindexLast;+    for (int i = 0; pindexFirst && i < nInterval-1; i++)+        pindexFirst = pindexFirst->pprev;+    assert(pindexFirst);++    // Limit adjustment step+    int64 nActualTimespan = pindexLast->GetBlockTime() - pindexFirst->GetBlockTime();+    int64 nTwoPercent = nTargetTimespan/50;+    //printf("  nActualTimespan = %"PRI64d"  before bounds\n", nActualTimespan);++    if (nActualTimespan < nTargetTimespan)  //is time taken for a block less than 3minutes?+    {+         //limit increase to a much lower amount than dictates to get past the pump-n-dump mining phase+        //due to retargets being done more often it also needs to be lowered significantly from the 4x increase+        if(nActualTimespan<(nTwoPercent*16)) //less than a minute?+            nActualTimespan=(nTwoPercent*45); //pretend it was only 10% faster than desired+        else if(nActualTimespan<(nTwoPercent*32)) //less than 2 minutes?+            nActualTimespan=(nTwoPercent*47); //pretend it was only 6% faster than desired+        else+            nActualTimespan=(nTwoPercent*49); //pretend it was only 2% faster than desired++        //int64 nTime=nTargetTimespan-nActualTimespan;+        //nActualTimespan = nTargetTimespan/2;+    }+    else if (nActualTimespan > nTargetTimespan*4)   nActualTimespan = nTargetTimespan*4;++    // Retarget+    CBigNum bnNew;+    bnNew.SetCompact(pindexLast->nBits);+    bnNew *= nActualTimespan;+    bnNew /= nTargetTimespan;+++    if (bnNew > bnProofOfWorkLimit)+        bnNew = bnProofOfWorkLimit;      /// debug print     printf("GetNextWorkRequired RETARGET\n"); The one week part of "one week or 2016 blocks" retargeting is b0rked.Downloading the chain with a fresh datadir makes it try to retarget at block 1.Then it tries to go back 2016 blocks. from block 1. Boom, NULL pointer.With a client that already has the blockchain up to some point in the past, it'll start disagreeing on what the target should be (again, mistrigger of the after-7-days stuff)... around now.Easy Fix: pull a Thomas and blatantly rip off solidcoins retargeting algo. If they're anything like the fans on these: http://www.newegg.com/Product/Product.aspx?Item=N82E16814102873Once they start "growling" the single sleeve bearing (!) is totally shot. Takes about 3-5 months at 100%.And there's no way to lubricate them.Whoever decided to put a cheap-ass sleeve bearing fan right on top of the hottest part of the heatsink was a true genius. That was a loooong time ago, nowadays it's < 1%. 50 != bulk.Hell, that's not even one tray. Clients don't spend 0/unconfirmed coins they get from somewhere else.They will spend their own 0/unconfirmed change if left no other option.Original reason for that, "viral bitdust":A transaction that split 0.01 btc into 100s of tiny outputs and had no fee, so it staid at 0/unconf "forever".Clients that received one of the outputs sooner or later used them as inputs in their own transactions... and as a tx can only go into a block if all its inputs are in the same or older blocks...Yeah. Simple, anyone mining back then and thinking like that most likely sold at $1. Target time/block doesn't enter this calculation (it only affects what difficulty a network will end up at at a given hashrate).Just block reward (thats where the 32 and 50 come from), difficulty and exchange rate.another way to put per-block reward, difficulty and exchange rate together:1 share on BTC gets you about 50/1806098 BTC = 0.000027684 btc/share1 share on SC at a exchage rate of 0.0017btc/sc gets you ... 32/2703*0.0017 BTC = 0.000020126 btc/share0.000020126 / 0.000027684 = 0.726990319 -> you're making about 27.3% less mining SC and selling em than mining BTC.now... what exchange rate do we need to come out even?50/1806098 = 32/2703*Xor...X = (50 / 1806098) / (32 / 2703)X = 0.002338432you can also swap things around to suit youX = (2703 / 32) / (1806098 / 50)X = 2703 / 1806098 * 50 / 32or replace the * 50 / 32 with * 1.5625X = 1.5625 * 2703 / 1806098... and it's stillX = 0.002338432Wonders of arithmetic! Err... No.At the time of your post, SC difficulty was about 2700(2.7k/32)/(1807k/50) = 0.00233467that's what btc/sc would have to be to end up +-0.at 0.0017btc/sc, you're making roughly 30% less mining SC. 24pin ATX has 2 +12V pins and 8 GND pins, rated for 6A each.So thats a max current of 12A on the 12V side, 48A on the return.That's the short version of why splitting out GND isn't needed. You realize a bitcoinhash is *2* sha256 blocks operations, right?Well, not exactly 2 thanks to some optimizations possibleyou can drop the last 3 rounds completely (they don't change H), and lose part of the previous round (you only need the E output of the 4th-to-last)Initial rounds can be optimized as well, as the last DWORD of hMerkleRoot and nTime/nBits don't change between loops, so you can drop the equivalent of ~3 rounds there as well.Same thing goes for optimizing/precalculating parts of the W mangling, as we're feeding in quite a bit of constants.Register access is basically free on GPUs (they mask reg r/w by pipelining 4 "threads" on the shader pipeline).Ch() can be done in 1 cycle, and Maj() in 2.Also, what LUT accesses? just hardcode the K constants in the instruction stream.So while you came up with a somewhat reasonable result, you did so by pure chance using invalid assumptions and numbers. I'd pile onto the "OC too high" heap, but...Look at the gpu-z log, that card is running stock 725/1000 clocks at stock voltage.Edit:core and vddc temps look ok, maybe a tad high for my taste.But 30% fanspeed? what do the VDDC temps on the slave GPU look like? Well, or just make sure to always leave at least a 0.01 balance or empty your wallet completely. There you go, now the faucet is giving away 500 again 
nope, they're perfectly valid new-testnet coins. just sent 20k to the faucet. well, if anyone needs a few, I still have 140k sitting around. 3 5970s at 800/300 are well < 900W, any half-decent 1.2kW should be able to handle that fine. I know of one bug in 0.3.24.When you do a send thats nearly your whole balance so1. change output is < 0.012. the inputs size * age is big enough so it doesn't require a fee due to "spammyness"3. the tx is small enough to not require a fee due to sizethe sub-cent change gets thrown away as fee instead of checking if paying the 0.0005 fee would end up cheaper.already got fixed in git Thinking out loud...Do we even need to check the ECDSA signatures in blocks older than the last checkpoint?Assuming the checkpoint hash is okay, you can't change any transactions in blocks before it without breaking the chain.Assuming the checkpoint hash was replaced (eve hacked the devs box or something)... we're pretty much fucked anyways as the client will reject the legit chain and stay on the attackers chain.Any input? Correct.Can't see any reason why that would be much weaker, really.Not too sure about that, I doubt revealing part of the pubkey long in advance is a problem. But then I'm not a cryptographer familiar with ECC, so I wouldn't bet the future of a currency on it. Yes, you should be seeing next to no hashrate drop with multiple GPUs (< 1%).5970s go into thermal throttling when core hits 100°C or the VRMs hit 125°C.But that shows up as random drops in hashrate, not a consistent slowdown.PSU issues tend to lead to lockups and BSODs, not cause reduced hashrate.Random shot in the dark, driver/sdk. Maybe try different/older catalyst versions? Been there, done that, got the t-shirt.Normal clients won't relay transactions that don't have enough fees, and normal miners won't include them in blocks.Of course they'll happily relay and accept transactions that have too much fee.So, to get a transaction without a fee that would require it into a block you have to:a) have enough hashpower to mine your own block.orb) directly connect to a miner/pool that accepts transactions with "not enough" fee.... I don't exactly see where the "HUGE SECURITY FLAW!!1!one" is supposed to be... Okay, 0.3.24-beta, yeah, that should be 0.3.24.I'm asking because iirc some older version right after min fee changed from 0.01 to 0.0005 (0.3.23 ?) had a bug where it would throw away any output < 0.01 as fee. that was fixed in git afterwards but then the fix got accidentally reverted and I'm not exactly sure when/if it was un-reverted again. Hell, now I'm not even sure if it's fixed in 0.3.24...And this tx looks exactly like it'd trigger that bug.Someone who's been following recent client changes more closely should be able to shed more light on this.Edit: just checked git, yes. that bug is in 0.3.24.fix is already in master, so hopefully this one will be fixed for good in 0.3.25-rc1. Is this your tx: http://blockexplorer.com/t/7AYvrSCyRK ?What version of the client were you running? 0.3.24? Shouldn't this be in meta? *ducks* Nah, just pushing his little "my failcoins are better than your failcoins" agenda. Nah, I'll be sitting on em until hell freezes over. I just like playing GPU progress quest. Had a bunch of lockups thanks to the NTP stuff, fixed by adding a timeout.Baseless personal attack. Or Mr. Oldtroll here has a magic crystal ball showing him the future actions of another person. Less of a scam than ixcoin? Obviously, simply for the reason of having no anonymous founder sitting on 500k coins.Not a scam? Well... not a *intentional* scam. Imo the whole thing will end up as a pyramid scheme with "investors" holding a bunch of worthless coins simply because it's a alternate blockchain bringing nothing of real value to the table.So... why did I mine it? Well... why not? I also threw > 10Ghps at testnet for a day just for fun. So now we're even too lazy to come up with original FUD and resort to copypasta. It's also flat out wrong.Maybe next time try using a miner that can handle > 1 longpoll/second and doesn't need half a eternity from finding a H==0 to submitting a share.I did that, got >700 of the early blocks with 6Ghps and a 180ms ping to io.btcguild. Eleu, small hint, when your i0coind crashes while performing a payout, don't assume it didn't go through. moved everything but 6.1Gh off again, have fun  That'd be quite a trick, considering there are only ~282k right now and I have > 33k...
Confirmed Rewards   29669.89232442*walks away whistling* 24Gh, but with massively lower latency than most GPU miners, really helps at low difficulty. Guess again. Me. Note that the P2P there refers to person-to-person. Basically yet another paypal/dwolla/... Nope.And the point still stands, your post history quite clearly shows that you are trying to scare away people from getting more GPUs. Get the salt shaker ready. And check his post history  I get about half that assuming vast majority of hashrate is ATI 5xxx GPUs.3Thps = about 8300 5870s = about 22.5PFLOPS peak single precision, 4.5PFLOPS peak double precision. Okay, so you fit "around" 1.5 engines on a chip. is it me or doesn't that make any sense at all?Edit:Yes, I make assumptions about sha256. it's sha256. the round function including W update needs at least 8 32 bit adders. no amount of "optimizing" changes that.And those "highly optimized" commercial cores? barely 120MHz on a S6, 65+ clocks/block, and you can maybe fit 70 on a LX150. 65Mh/s wooo... Okay, so now you're fitting 2 pipelined engines on a LX150.need 120 rounds, thanks to cheating with W updates etc you can get it down to ~6 32 bit adders per round avg, times 120 ... 720 or so 32 bit adders per engine, 1440 adders.So *only* a bit over 100% slice utilization of a LX150, just for the adders. Yeah, sure. Trying to make any sense of this.a) You have a 120+ stage unrolled pipelined engine at 133MHz. You fit 1.58 of em? what the hell is 0.58 of a engine?b) You have a single registered round running at 133MHz. one bitcoinhash = double-sha256 takes 128 or so clocks. you fit 200 of those - ~ 208Mh/s.let's assume Byou need to store at least a..h and W 0..15, that's 24*32 = 768 FFs per engine.times 200 engines. thats 153600 FFsa S3-5000 has 66560 FFs... nopea S6 LX100 has 126576 FFs... still nopea S6 LX150 has 184304 FFs... 83% utilization just for the storage FFs. far edge of plausibleFor adder utilization it gets hilarious, you need at least 8 32-bit adders per round.Times 200 single-round engines thats 1600 32bit adders...half of a S6s slices have carry logic, each of those can do 4 bits of a adder, that's a max of 988 32 bit adders on a S6 LX100, 1439 on a LX150... we need 1600... ?!?I have the sneaking suspicion someone didn't realize one bitcoinhash = 2 sha256 blocks... Thanks for the correction, noted. Wrong. For rough estimates, 1 bitcoin Ghps = about 8TFLOPS. One bitcoinhash is ~4100 32 bit integer ops on ati 5/6xxx, and SP FLOPS on any recent arch = 2 * INTOPS.so at 700Gh/s, about 5.6 PFLOPS or so.Tianhe-1A has 4.7PFLOPS peak according to top500, so for peak values, yup, faster than worlds fastest known supercomputer.That google number is from 2008, though 500k machines sounds awfully low. So... no clue.For F@H ... Hard to compare, they don't have peak stats, guessing ~75% efficiency they're about 2x bitcoins current throughput.Any multi-million-machine botnet? botnet wins. Same #ALUs as a 5450, 500 instead of 650 MHz clock, so I'd expect about 9.2 Mh/s 114974     OverlordQ     03-25-2011 10:55:45     --  02h 06m 25s     Confirmedhttp://bitcoinpool.com/block.php?block=114974 ->http://blockexplorer.com/b/114974 ->http://blockexplorer.com/block/000000000000da97d2ba7ddb5d3c9b48980b92bb12f3926bb0382615853fbacacontaining generation http://blockexplorer.com/tx/0db08f91bef092708054d340e698986cdac83dbeaaee91f8fe7b94b6b6dcd285which was sent to SLUSHS pool main addr 1PJnjo4n2Rt5jWTUrCRr4inK2XmFPXqFC7 in tx http://blockexplorer.com/tx/67e8af21b9759571a95b2f73926ccdb59d5fd625acddeb20533c52429efd243e Pwned.Glass house, meet stone  Still pretty bad.That GPU should be capable of ~ 68Mhash/s. Good?I've gotten 70Mh/s with a Spartan6 LX 150-3, $180 @ 1ea.he gets the same from a CycloneIII 120-C8, $380 @ 1ea.and expects about the same from a CycloneIV-E 115-C8, $310 @ 1ea. Another onesetaccount    CRITICAL_BLOCK(cs_mapAddressBook)        GetAccountAddress(strOldAccount)            CRITICAL_BLOCK(cs_mapWallet)processmessages:CRITICAL_BLOCK(cs_main)    ProcessMessage(pfrom, strCommand, vMsg)        AddToWalletIfMine()              AddToWallet(wtx)                  CRITICAL_BLOCK(cs_mapWallet)                      walletdb.WriteName(PubKeyToAddress(vchDefaultKey), "")                          CRITICAL_BLOCK(cs_mapAddressBook)
well, quick manual check suggests for cs_main + cs_mapWallet only rpc.cpp sendfrom and sendmany are doing the wrong thing. I think we got a deadlock in there...rpc:sendfrom    CRITICAL_BLOCK(cs_mapWallet)        SendMoneyToBitcoinAddress(strAddress, nAmount, wtx)            SendMoney(scriptPubKey, nValue, wtxNew, fAskFee)                CRITICAL_BLOCK(cs_main)                    ...processmessages:CRITICAL_BLOCK(cs_main)    ProcessMessage(pfrom, strCommand, vMsg)        AddToWalletIfMine()              AddToWallet(wtx)                  CRITICAL_BLOCK(cs_mapWallet) Yes, only once every 60 seconds.note that CreateNewBlock holds cs_main and cs_mapTransactions while doing its thing.So it not only blocks RPC for that time, but also processing and sending of p2p messages and ... really, pretty much everything.On a decent box with 1500 cached tx, it takes 1.7 seconds.In extreme cases (lots of cached tx, slow cpu, low free memory so a decent % of reads actually have to hit disk), well north of 10 seconds.And it's entirely avoidable. it's ECDSA using secp256k1 curve, so 2128 not 280. According to sun, T2 can do "32 Gb/s/chip" for SHA-1let's just assume it's as fast for SHA-256.let's further assume it's magic and has 0 setup cost.SHA256 block size is 512 bits, so 32Gb/s / 512 = 62.5M sha256 blocks/sone bitcoinhash is 2 sha256 blocks, so 62.5M / 2 = 31.25Mhash/s.Not bad for a crypto accel.A $110 HD5770 does > 5x that. Thread necromancy.Pretty much all of those are really low-scoring penny spam, legit free transactions should still get into blocks quick enough thanks to dPriority. Yeah, typo, meant 2*2858T = ~ 5700TFLOP/scurrent estimated network speed is all over the place depending on if you use difficulty, 1-day avg, 1-week avg or whateverso "somewhere around 5-6 PFLOP/s"[edit]argh, 2*2858T = ~ 5700TFLOP/s, not G 5.8 petaflops, or 5800 teraflops...on pretty much all recent archs with vector units, one 32-bit INTOP = 2 single precision FLOPone bitcoinhash is ~6.35k x86 INTOP450G hash/s * 6.35k INTOP/hash = 2858T INTOP/s2858T INTOP/s * 2 FLOP/INTOP = ~6700T FLOP/s Saw the same shit with 5970s and SDK 2.2 and 2.3.SDK 2.1 + fglrx 10.9 - 10.11 works fine. It's not that hard to calculate.We have 6 SPEs available, each can do one 4*32 bit vector op/clock. clocked at 3.2GHz.6 * 4 * 3.2G = 76.8GINTOPsNo native bitrotate, no ch()-like opcode, so we need about 6350 ops/bitcoinhash.76800M / 6350ops/hash = ~ 12.1 Mhash/sNot THAT bad for a >5 year old design.About on par with a modern CPU, completely outclassed even by a midrange GPU.PS3: 12.1Mh/s, ~80W, ~$250HD5770: 156.8Mh/s, ~110W, ~$130 No it doesn't, unless those other miners are already running very close to break-even.Less profit > zero profit. Yep, that works.You still can't tell a scratchoff spend from a normal transaction, so assuming scratchoffs come in 50btc sizes, an attacker has to try that for every 50btc transaction he sees.Of course attacker can also choose different time/space tradeoff (store 2**40 points, 2**24 add G + lookup ...).Random idea: what if you make code->secret more costly, let's say pbkdf2-hmac-sha256 with 100k iterations?that way a simple airthmetic lookup table wont work anymore, you'd have to pretty much create a few arbitrary pubkey->code functions and build rainbow tables.as the tx really only needs to be secure enough to make it economically uninteresting to break it before it gets into a block (attacker needs to find privkey, create double-spend, get THAt into a block before the orig tx makes it into a block...). yeah, that disables hardware video accel for flash, use any other media played that uses it and it's back to 400Mhz clock though. Other, he is a troll and a constant source of amusement. The problem iirc is, if anything uses gpu video acceleration, ATI driver switches to "media playback" clock, which is 400 core/max mem.Possible solutions:a) enable overdrive, manually edit the overdrive config .xml to change state 2 core clock to state 0 core clockb) use RBE to hack the cards BIOS and change the clocks/voltages for the 400 mhz core/max mem clock state there to have same high core clk as normal 3d mode state. published FLOPS for GTX580: 1581.1G512 ALUs * 1544 MHz shader clock * 2 (muladd factor) = 1581.056Gpublished FLOPS for HD5970: 4640G3200 ALUs * 725MHz * 2 (muladd factor) = 4640Ghey, what a coincidence! off-by-3-orders-of-magnitude.HD5xxx needs about 4150 integer operations per hashHD4xxx and nvidia 2/4/5xx about 6350 integer operations.for all current architectures integer ops/second = number of shader ALUs * clock.so a 5870 at 1600 ALUs * 850MHz = 1360000M intops/second, / 4150 = ~ 327.7Mh/s4870: 800 * 750M / 6350 = ~ 94.5 Mh/sGTX580: 512 * 1544M / 6350 = ~ 124.5Mh/setc...usually published FLOPS numbers are simply intops * 2 (one muladd counts as 2 operations). In a remote buffer overflow scenario all nodes participating in the normal p2p network are pretty much fucked, no matter if they accept incoming connections or not.Consider the following scenario:Attacker exploits bug and disables all public nodes allowing incoming connections.Nodes *not* allowing incoming connections see their outgoing connections count dropping and try to connect to new peers.Only nodes left accepting incoming connections are under control of the attacker and exploit same bug in nodes connecting to them.Whoops. http://download2-developer.amd.com/amd/Stream20GA/ati-stream-sdk-v2.1-vista-win7-32.exehttp://download2-developer.amd.com/amd/Stream20GA/ati-stream-sdk-v2.1-vista-win7-64.exehttp://download2-developer.amd.com/amd/Stream20GA/ati-stream-sdk-v2.1-xp32.exehttp://download2-developer.amd.com/amd/Stream20GA/ati-stream-sdk-v2.1-xp64.exehttp://download2-developer.amd.com/amd/Stream20GA/ati-stream-sdk-v2.1-lnx32.tgzhttp://download2-developer.amd.com/amd/Stream20GA/ati-stream-sdk-v2.1-lnx64.tgzhttp://download2-developer.amd.com/amd/Stream20GA/ati-stream-sdk-v2.2-vista-win7-32.exehttp://download2-developer.amd.com/amd/Stream20GA/ati-stream-sdk-v2.2-vista-win7-64.exehttp://download2-developer.amd.com/amd/Stream20GA/ati-stream-sdk-v2.2-xp32.exehttp://download2-developer.amd.com/amd/Stream20GA/ati-stream-sdk-v2.2-xp64.exehttp://download2-developer.amd.com/amd/Stream20GA/ati-stream-sdk-v2.2-lnx32.tgzhttp://download2-developer.amd.com/amd/Stream20GA/ati-stream-sdk-v2.2-lnx64.tgzhttp://download2-developer.amd.com/amd/Stream20GA/ati-stream-sdk-v2.3-vista-win7-32.exehttp://download2-developer.amd.com/amd/Stream20GA/ati-stream-sdk-v2.3-vista-win7-64.exehttp://download2-developer.amd.com/amd/Stream20GA/ati-stream-sdk-v2.3-xp32.exehttp://download2-developer.amd.com/amd/Stream20GA/ati-stream-sdk-v2.3-xp64.exehttp://download2-developer.amd.com/amd/Stream20GA/ati-stream-sdk-v2.3-lnx32.tgzhttp://download2-developer.amd.com/amd/Stream20GA/ati-stream-sdk-v2.3-lnx64.tgz[Edit]Fixed typo in one of the 2.3 URLs Eww, no shielding, 50mil ribbon, cheap 2-layer boards.http://www.dhgate.com/pci-e-express-16x-riser-flexible-cable-extender/p-ff8080812c3058d5012c3681e2865f3b.htmlIf you want something with a at least a chance to work at 2.0 speeds, look for chinese clone of ADEX PE-FLEX16.http://www.dhgate.com/pci-e-express-x16-riser-card-1-slot-with/p-ff8080812c305fe5012c367decb86967.html
It's poisson.Remember, if events in a fixed timespan is poisson, time between events is a exponential distribution. These are my private miner versions.clmine is my old OpenCL miner, should be about as fast as older versions of m0 or diablo.clmine2 is my newer OpenCL miner, roughly on par with current m0 or diablo.calmine is a CAL IL miner with BFI_INT, closest thing would be mrbs miner. DO NOT USE THAT PROGRAM, IT IS A TROJAN I think that could be fixed by only allowing replacing a transaction with one where inputs and outputs are a strict superset of the original.So you could replace [some set of inputs] -> 80 to A, 20 to B with [some set of inputs + some more inputs] -> 80 to A, 20 to B, 9 to X, 1 fee.Unless I'm missing something, that shouldn't make trusting 0-unconf transactions any more risky than it currently is. It's throttling because the VRMs are hitting 120°C.see http://www.anandtech.com/show/3590, bitcoin mining is about as bad as dnet.Sadly, for aircooling stock is as good as it gets. The only 3rd party air cooler for 5970 is AC Accelero 5970, and its VRM cooling is *worse* than stock.So a) go watercooling or b) fiddle around with more case airflow, fans pointed at rear of the card, ..., finally say fuck it and lower Vcore. Quick estimate for Cell:7 SPE SIMDs + PPE AltiVec, each doing 4*32-bit ops/cycle.PS3 cell is clocked @ 3.2GHz.bitcoinhash is ~6350 cycles without native rotate.8 * 4 * 3.2G / 6350 -> about 16M hash/s.About on par with a hexcore K10. base64 encodedzlib deflate -9 compressedbase64 encodedresult looks like binary junk with php code fragments. Hrrrm, could this be caused by the asm in CallCPUID? CPUID clobbers ebx and edx, yet we don't seem to be saying so... The real issue on FPGA isnt the logic ops(cheap) or the rotates(pretty much free), but the 32-bit adds.A_out = H + s0 + s1 + maj + ch + K + W-> at least 3 level adder tree ((H + s0) + (s1 + maj)) + ((ch + K) + W)Carry chain delay in a single 32-bit adder on a -3 speed grade Spartan6 is ~2ns, so without ANY routing delays we're already limited to 166MHz.Real-world you're lucky to get 80MHz out of a non-pipelined round on a -3 S6Pipelinining a round to 2 or 3 stages helps, but increases FF usage a LOT (you have to carry 256 bits of A..H, 512 bits of W[0..15] and the initial A..H for the final add around).2-stage gives ~140MHz on a -3, 3-stage ~180MHz= a 2-stage pipelined sha256 round is ~1k FFs, 3-stage pipelined ~1.5k FFsXC6SLX150 has something like 160k FFs available, and the synthesis tools pretty much throw speed out the window once you go >70% FF utilization.so realistically you MIGHT be able to fit 64 2-pipelined rounds of sha256 on a LX150, 2 clocks/bitcoinhash @ 140MHz -> 70Mh/sor maybe with lots of luck and sacrificing a chicken to the place and route gods 48 rounds 3-stage @ 180MHz -> 68Mh/s= 70Mh/s on a -3 speed grade XC6SLX150, 20%-30% less on a -2 speed grade.so 9 grand for MAYBE 850Mh/s... a $500 HD5970 can get >550Mh/s stock, well >600Mh/s OCed at stock voltage even on a "bad" card.okay, let's be REALLY generous, assume we can magically get 1.2Gh/s out of 12 150-2s and they consume NO POWER AT ALL.So how long does it take at 600W for 2 5970s and $0.10/kWh to make up that $8k price difference? 0.6kW @ $0.10 kWh = $1.44/day ... about 15 years. 300MHz? on a Spartan3? Oh, and bitcoin hash is TWO rounds of sha256.I just synthesized it, 60MHz max for one core on a -5 speed grade S3E-500.So NOT300MHz / 80 clocks/hash * 3 cores = 11MHpsinstead (assuming we can lose overhead and just have to do a mid-add and a compare)60MHz / 130 clocks/hash * 3 cores = 1.4MHpsat $20/chip thats 0.07MH/$ or about 25x worse than a HD5970...and for "GPU needs mainboard".. FPGA needs PCB, VRMs, config memory, some kind of host connection, ...So yeah, pull a few crazy numbers out of your ass and FPGAs look decent. Math fail much?OCed HD5970 = 625Mh/s at 325W625Mh/s @ 12252 difficulty is 23.5h/block23.5h * 0.325kW = 7.64kWh per block7.64kWh @ $0.10/kWh = $0.7641 block @ $0.19/BTC = $9.50yeah, *totally impossible* how it could be still profitable at current price and < 12.5x current difficulty.And of course theres NO places with even cheaper power. No sir! Must be evil zombie herders! 9400GT 16SPs @ 1.4GHz9800GT 112SPs @ 1.5GHz-> a 9800GT is about 7.5x 9400GT ... The difference between new and older CPUs is pretty easy to explain.Older microarchitectures have 64-bit mmx/sse execution units and split 128bit sse ops into 2 64bit microops.Newer archs have 128bit sse units.AMD K8: 2 64bit unitsintel Core/Core2: 3 64bit unitsAMD K10: 2 128bit unitsintel nehalem: 3 128bit unitsK10 = Opterons with 4 or more cores, Phenom, Phenom II, Athlon IInehalem = xeon 34xx/35xx/36xx/55xx/56xx/65xx/75xx, i3/i5/i7 Total number of peer connections, outgoing is still limited to 8. Fix is in svn r124, r125 added -maxconnections. Just had a "fun" gdb session with the official 0.3.8 linux 64 bit binary on debian sid.Same bug, output state on return from SHA256Transform always == initial state.So... did someone really generate a block running the official 0.3.8 64 bit linux binary (the one in bin/64)?Oh, and from a quick glance at the svn changelog, that bug probably has been there since r118 = 0.3.6.Oh, and who THE FUCK thought stripping the official binary was a good idea? I just wasted half an hour hunting down SHA256Transform in a disassembler. At ~ 8Mhash/s combined not generating a block at 1.0 diff in over 1h is pretty unlikely.As in, under 0.1% probability unlikely (50% is ~6 min, 1% ~42 min)<edit>Forgot to mention, he's running a custom compile of stock 0.3.8 sources. Always had that problem building under Debian sid amd64.just add -l Xxf86vm to WXLIBS in makefile.unix OT, butThat's only gonna work if your platform is 100% secure from the bottom up.Your app can't check its own signature, because someone could simply modify the check.So the OS has to check the apps signature, but someone could modify the OS.So the bootloader has to check the OSes signature, but someone could modify the bootloader.So the BIOS has to check the bootloaders signature, but someone could modify the BIOS.So the hardware itself has to check the BIOSes signature, and finally it's secure.But if any component in the chain has a vulnerability that allows someone to modify it (at load or runtime) without getting detected by the lower level, game over.See various console modchips/softmods, iphone unlocking, ... this is my quick and dirty reference implementation for python, tested against bitcoins implementation for -256...256 and with about 4000 random numbers varying in size from 8-256 bits.Writing a faster and more pythonic version should be pretty easy, but I can't be arsed right now...Code:import structdef mpi2num(m): """convert MPI string to number""" datasize = struct.unpack(">I", m[0:4])[0] r = 0 if datasize:  neg_flag = bool(ord(m[4]) & 0x80)  r = ord(m[4]) & 0x7F  for i in xrange(1, datasize):   r <<= 8   r += ord(m[4+i])  if neg_flag:   r = -r return rdef num2mpi(n): """convert number to MPI string""" if n == 0:  return struct.pack(">I", 0) r = "" neg_flag = bool(n < 0) n = abs(n) while n:  r = chr(n & 0xFF) + r  n >>= 8 if ord(r[0]) & 0x80:  r = chr(0) + r if neg_flag:  r = chr(ord(r[0]) | 0x80) + r[1:] datasize = len(r) return struct.pack(">I", datasize) + rdef GetCompact(n): """convert number to bc compact uint""" mpi = num2mpi(n) nSize = len(mpi) - 4 nCompact = (nSize & 0xFF) << 24 if nSize >= 1:  nCompact |= (ord(mpi[4]) << 16) if nSize >= 2:  nCompact |= (ord(mpi[5]) << 8) if nSize >= 3:  nCompact |= (ord(mpi[6]) << 0) return nCompactdef SetCompact(nCompact): """convert bc compact uint to number""" nSize = (nCompact >> 24) & 0xFF tbuf = "\x00\x00\x00" + chr(nSize) if nSize >= 1:  tbuf += chr((nCompact >> 16) & 0xFF) if nSize >= 2:  tbuf += chr((nCompact >> 8) & 0xFF) if nSize >= 3:  tbuf += chr((nCompact >> 0) & 0xFF)  tbuf += "\x00" * (nSize - 3) return mpi2num(tbuf)
